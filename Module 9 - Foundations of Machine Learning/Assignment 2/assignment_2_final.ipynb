{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, silhouette_score, silhouette_samples\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='tensorflow')\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the MNIST Data Set \n",
    "\n",
    "def load_mnist_data():\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "    n_train = X_train.shape[0]\n",
    "    n_test = X_test.shape[0]\n",
    "\n",
    "    # Normalise images to range [-1, 1]\n",
    "    X_train = X_train / 127.5 - 1\n",
    "    X_test = X_test / 127.5 - 1\n",
    "\n",
    "    # Flatten 28x28 images to 784 dimensional vectors\n",
    "    features_count = np.prod(X_train.shape[1:])\n",
    "    X_train_flatened = X_train.reshape(n_train, features_count)\n",
    "    X_test_flatened = X_test.reshape(n_test, features_count)\n",
    "\n",
    "    return X_train_flatened, X_test_flatened, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1 Code\n",
    "\n",
    "def load_and_prepare_data(subset, subset_size):\n",
    "    (X_train, y_train), (_, _) = mnist.load_data()\n",
    "    n_train = X_train.shape[0]\n",
    "    X_train = X_train / 127.5 - 1  \n",
    "    X_train = X_train.reshape(n_train, -1) \n",
    "    if subset:\n",
    "        indices = np.random.choice(n_train, subset_size, replace=False)\n",
    "        X_train = X_train[indices]\n",
    "        y_train = y_train[indices]\n",
    "    return X_train, y_train\n",
    "\n",
    "def apply_pca(X_train_subset):\n",
    "    pca = PCA(n_components=2) \n",
    "    X_train_pca = pca.fit_transform(X_train_subset)\n",
    "    return X_train_pca\n",
    "\n",
    "def plot_pca_scatter(X_train_pca, y_train_subset):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    scatter = plt.scatter(X_train_pca[:, 0], X_train_pca[:, 1], c=y_train_subset, cmap='tab10', alpha=0.6, s=10)\n",
    "    plt.colorbar(scatter, label='Digit Class')\n",
    "    plt.title('PCA Projection of MNIST Dataset')\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.show()\n",
    "\n",
    "def plot_ellipses_and_centroids(X_train_pca, y_train_subset):\n",
    "    # Helper function to draw confidence ellipses\n",
    "    def plot_ellipse(mean, cov, colour, ax):\n",
    "        eigenvalues, eigenvectors = np.linalg.eigh(cov)\n",
    "        order = eigenvalues.argsort()[::-1]\n",
    "        eigenvalues, eigenvectors = eigenvalues[order], eigenvectors[:, order]\n",
    "        angle = np.degrees(np.arctan2(*eigenvectors[:,0][::-1]))\n",
    "        width, height = 2 * np.sqrt(5.991 * eigenvalues)\n",
    "        ell = Ellipse(xy=mean, width=width, height=height, angle=angle, edgecolor=colour, fill=False, linewidth=2)\n",
    "        ax.add_patch(ell)\n",
    "\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    for digit in range(10):\n",
    "        points = X_train_pca[y_train_subset == digit]\n",
    "        mean = np.mean(points, axis=0)\n",
    "        cov = np.cov(points, rowvar=False)\n",
    "        colour = plt.cm.tab10(digit)\n",
    "        plt.scatter(points[:, 0], points[:, 1], c=[colour], alpha=0.1, s=10)\n",
    "        plt.scatter(mean[0], mean[1], c=[colour], marker='x', s=100, label=f'Digit {digit}')\n",
    "        plot_ellipse(mean, cov, colour, plt.gca())\n",
    "    plt.title('PCA of MNIST with Centroids and 95% Confidence Ellipse Outlines')\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def pairwise_separability(X_pca, y):\n",
    "    results = []\n",
    "    for d1, d2 in itertools.combinations(range(10), 2):\n",
    "        idx = (y == d1) | (y == d2)\n",
    "        svm = LinearSVC(max_iter=10000)\n",
    "        svm.fit(X_pca[idx], y[idx])\n",
    "        acc = accuracy_score(y[idx], svm.predict(X_pca[idx]))\n",
    "        results.append((d1, d2, acc))\n",
    "    \n",
    "    # Sort by accuracy in descending order\n",
    "    sorted_results = sorted(results, key=lambda x: -x[2])\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    pairs = [f\"{d1}-{d2}\" for d1, d2, _ in sorted_results]\n",
    "    accuracies = [acc for _, _, acc in sorted_results]\n",
    "    \n",
    "    plt.bar(pairs, accuracies, color='skyblue')\n",
    "    plt.axhline(y=np.mean(accuracies), color='r', linestyle='--', label=f'Mean Accuracy: {np.mean(accuracies):.3f}')\n",
    "    plt.ylim(0.5, 1.05)\n",
    "    plt.xlabel('Digit Pairs')\n",
    "    plt.ylabel('Classification Accuracy')\n",
    "    plt.title('Pairwise Digit Separability using SVM on PCA Features')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def compute_distribution_stats(X_pca, y):\n",
    "    stats = []\n",
    "    for digit in range(10):\n",
    "        points = X_pca[y == digit]\n",
    "        centroid = points.mean(axis=0)\n",
    "        var_pc1, var_pc2 = points.var(axis=0)\n",
    "        stats.append([digit, round(centroid[0], 2), round(centroid[1], 2), round(var_pc1, 2), round(var_pc2, 2), len(points)])\n",
    "    display(pd.DataFrame(stats, columns=['Digit', 'Centroid_PC1', 'Centroid_PC2', 'Var_PC1', 'Var_PC2', 'N_Samples']))\n",
    "\n",
    "def run_task1(subset=True, subset_size=10000):\n",
    "    X_train, y_train = load_and_prepare_data(subset, subset_size)\n",
    "    X_train_pca = apply_pca(X_train)\n",
    "    plot_pca_scatter(X_train_pca, y_train)\n",
    "    plot_ellipses_and_centroids(X_train_pca, y_train)\n",
    "    pairwise_separability(X_train_pca, y_train)\n",
    "    compute_distribution_stats(X_train_pca, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Task 1\n",
    "\n",
    "run_task1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2 Code\n",
    "\n",
    "def predict(x, w, b):\n",
    "    z = np.dot(x, w) + b\n",
    "    prediction = np.sign(z)\n",
    "    prediction[prediction == 0] = 1\n",
    "    return prediction\n",
    "\n",
    "def optimise(x, y, w, b, max_iter, tol, learning_rate):\n",
    "    n, m = x.shape\n",
    "\n",
    "    # Initialise weights if none provided\n",
    "    if w is None:\n",
    "        w = np.random.randn(m) * 0.01\n",
    "    if b is None:\n",
    "        b = np.random.randn() * 0.01\n",
    "\n",
    "    iter_count = 0\n",
    "    error_history = []\n",
    "    error = float('inf')\n",
    "\n",
    "    while iter_count < max_iter and error > tol:\n",
    "        y_pred = predict(x, w, b)\n",
    "        error = np.mean(y_pred != y)\n",
    "        error_history.append(error)\n",
    "\n",
    "        if error <= tol:\n",
    "            break\n",
    "\n",
    "        # Update weights for misclassified samples\n",
    "        misclassified_indices = np.where(y_pred != y)[0]\n",
    "        for i in misclassified_indices:\n",
    "            w += learning_rate * y[i] * x[i]\n",
    "            b += learning_rate * y[i]\n",
    "\n",
    "        iter_count += 1\n",
    "\n",
    "    return w, b, error_history\n",
    "\n",
    "def evaluate_perceptron(x_train, y_train, x_test, y_test, max_iter, tol, lr):\n",
    "    w, b, error_history = optimise(\n",
    "        x_train, y_train,\n",
    "        w=None,\n",
    "        b=None,\n",
    "        max_iter=max_iter,\n",
    "        tol=tol,\n",
    "        learning_rate=lr\n",
    "    )\n",
    "\n",
    "    # Evaluate on training set\n",
    "    y_train_pred = predict(x_train, w, b)\n",
    "    train_accuracy = np.mean(y_train_pred == y_train)\n",
    "\n",
    "    # Evaluate on test set\n",
    "    y_test_pred = predict(x_test, w, b)\n",
    "    test_accuracy = np.mean(y_test_pred == y_test)\n",
    "\n",
    "    return {\n",
    "        'train_accuracy': train_accuracy,\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'weights': w,\n",
    "        'bias': b,\n",
    "        'error_history': error_history\n",
    "    }\n",
    "\n",
    "def visualise_weights(w, shape, digit_pair):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    weight_img = w.reshape(shape)\n",
    "\n",
    "    # Plot raw weights heatmap\n",
    "    plt.subplot(1, 2, 1)\n",
    "    im = plt.imshow(weight_img, cmap='viridis')\n",
    "    plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "    plt.title(f'Weights for {digit_pair[0]} vs {digit_pair[1]}')\n",
    "\n",
    "    # Create composite image with red for positive weights and blue for negative\n",
    "    composite = np.zeros((*shape, 3))\n",
    "    pos_weights = np.copy(weight_img)\n",
    "    neg_weights = np.copy(weight_img)\n",
    "\n",
    "    pos_weights[pos_weights < 0] = 0\n",
    "    neg_weights[neg_weights > 0] = 0\n",
    "    neg_weights = np.abs(neg_weights)\n",
    "\n",
    "    if pos_weights.max() > 0:\n",
    "        composite[:, :, 0] = pos_weights / pos_weights.max()  # Red channel\n",
    "    if neg_weights.max() > 0:\n",
    "        composite[:, :, 2] = neg_weights / neg_weights.max()  # Blue channel\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(composite)\n",
    "    plt.title(f'Composite: (Blue={digit_pair[0]}, Red={digit_pair[1]})')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def prepare_binary_data(digit1, digit2, X_train, y_train, X_test, y_test):\n",
    "    # Filter data to keep only the two digits and label as -1 and +1\n",
    "    cond = (y_train == digit1) | (y_train == digit2)\n",
    "    x_train_bin = X_train[cond]\n",
    "    y_train_bin = y_train[cond].astype(float)\n",
    "    y_train_bin[y_train_bin == digit1] = -1\n",
    "    y_train_bin[y_train_bin == digit2] = +1\n",
    "\n",
    "    cond_test = (y_test == digit1) | (y_test == digit2)\n",
    "    x_test_bin = X_test[cond_test]\n",
    "    y_test_bin = y_test[cond_test].astype(float)\n",
    "    y_test_bin[y_test_bin == digit1] = -1\n",
    "    y_test_bin[y_test_bin == digit2] = +1\n",
    "\n",
    "    return x_train_bin, y_train_bin, x_test_bin, y_test_bin\n",
    "\n",
    "def run_digit_pair_experiments(digit_pairs, X_train, y_train, X_test, y_test, max_iter, tol, lr):\n",
    "    results = {}\n",
    "\n",
    "    for (digit1, digit2) in digit_pairs:\n",
    "        print(f\"\\n--- Perceptron for digit pair {digit1} vs {digit2} ---\")\n",
    "\n",
    "        x_train_bin, y_train_bin, x_test_bin, y_test_bin = prepare_binary_data(\n",
    "            digit1, digit2, X_train, y_train, X_test, y_test\n",
    "        )\n",
    "\n",
    "        result = evaluate_perceptron(\n",
    "            x_train_bin, y_train_bin,\n",
    "            x_test_bin, y_test_bin,\n",
    "            max_iter=max_iter, tol=tol, lr=lr\n",
    "        )\n",
    "        results_key = f\"{digit1}_vs_{digit2}\"\n",
    "        results[results_key] = result\n",
    "\n",
    "        print(f\"  Training Accuracy: {result['train_accuracy']:.4f}\")\n",
    "        print(f\"  Test Accuracy: {result['test_accuracy']:.4f}\")\n",
    "\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.plot(result['error_history'], marker='o')\n",
    "        plt.title(f'Error Curve: {digit1} vs {digit2}')\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('Misclassification Error')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "        visualise_weights(result['weights'], shape=(28, 28), digit_pair=(digit1, digit2))\n",
    "\n",
    "    return results\n",
    "\n",
    "def visualise_experiment_results(results):\n",
    "    pairs = []\n",
    "    train_accs = []\n",
    "    test_accs = []\n",
    "    iterations = []\n",
    "\n",
    "    for pair_key, res in results.items():\n",
    "        pairs.append(pair_key)\n",
    "        train_accs.append(res['train_accuracy'])\n",
    "        test_accs.append(res['test_accuracy'])\n",
    "        iterations.append(len(res['error_history']))\n",
    "\n",
    "    df_results = pd.DataFrame({\n",
    "        'Digit Pair': pairs,\n",
    "        'Train Accuracy': train_accs,\n",
    "        'Test Accuracy': test_accs,\n",
    "        'Iterations': iterations\n",
    "    })\n",
    "\n",
    "    df_display = df_results.copy()\n",
    "    df_display['Train Accuracy'] = df_display['Train Accuracy'].round(3)\n",
    "    df_display['Test Accuracy'] = df_display['Test Accuracy'].round(3)\n",
    "    \n",
    "    print(\"\\n----- Perceptron Results -----\")\n",
    "    display(df_display)\n",
    "\n",
    "    # Sort by test accuracy for better visualisation\n",
    "    sorted_indices = np.argsort(test_accs)\n",
    "    sorted_pairs = [pairs[i] for i in sorted_indices]\n",
    "    sorted_train_accs = [train_accs[i] for i in sorted_indices]\n",
    "    sorted_test_accs = [test_accs[i] for i in sorted_indices]\n",
    "    \n",
    "    # Calculate difference between train and test\n",
    "    acc_diff = [train - test for train, test in zip(sorted_train_accs, sorted_test_accs)]\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8), gridspec_kw={'height_ratios': [3, 1]})\n",
    "    \n",
    "    # Bar chart of accuracies\n",
    "    bar_width = 0.35\n",
    "    index = np.arange(len(pairs))\n",
    "    bars1 = ax1.bar(index, sorted_train_accs, bar_width, label='Train Acc', color='skyblue')\n",
    "    bars2 = ax1.bar(index + bar_width, sorted_test_accs, bar_width, label='Test Acc', color='orange')\n",
    "\n",
    "    ax1.set_xlabel('Digit Pairs')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.set_title('Perceptron Performance by Digit Pair')\n",
    "    ax1.set_xticks(index + bar_width / 2)\n",
    "    ax1.set_xticklabels(sorted_pairs, rotation=45)\n",
    "    ax1.set_ylim(0.5, 1.05)\n",
    "    ax1.legend()\n",
    "    ax1.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar in bars1:\n",
    "        height = bar.get_height()\n",
    "        ax1.annotate(f'{height:.3f}',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3), \n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', rotation=0, fontsize=9)\n",
    "    \n",
    "    for bar in bars2:\n",
    "        height = bar.get_height()\n",
    "        ax1.annotate(f'{height:.3f}',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  \n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', rotation=0, fontsize=9)\n",
    "    \n",
    "    # Plot showing train-test accuracy gap\n",
    "    bars3 = ax2.bar(index, acc_diff, bar_width*2, color=['green' if x <= 0.05 else 'red' for x in acc_diff])\n",
    "    ax2.set_xlabel('Digit Pairs')\n",
    "    ax2.set_ylabel('Train-Test Gap')\n",
    "    ax2.set_title('Difference Between Train and Test Accuracy')\n",
    "    ax2.set_xticks(index)\n",
    "    ax2.set_xticklabels(sorted_pairs, rotation=45)\n",
    "    ax2.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    ax2.axhline(y=0.05, color='black', linestyle='--', alpha=0.7, label='Threshold (0.05)')\n",
    "    ax2.legend()\n",
    "    \n",
    "    for bar in bars3:\n",
    "        height = bar.get_height()\n",
    "        ax2.annotate(f'{height:.3f}',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  \n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return df_results\n",
    "\n",
    "def run_task2(digit_pairs, max_iter=1000, tol=1e-3, learning_rate=0.01):\n",
    "    X_train, X_test, y_train, y_test = load_mnist_data()\n",
    "\n",
    "    results = run_digit_pair_experiments(\n",
    "        digit_pairs,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        max_iter=max_iter,\n",
    "        tol=tol,\n",
    "        lr=learning_rate\n",
    "    )\n",
    "\n",
    "    visualise_experiment_results(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Task 2\n",
    "\n",
    "digit_pairs = [(1, 0), (8, 3), (4, 9), (8, 7), (2, 9)]\n",
    "\n",
    "run_task2(digit_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3 Code \n",
    "\n",
    "def create_mlp(input_shape, hidden_units, output_units):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.InputLayer(input_shape=(input_shape,)))\n",
    "\n",
    "    for units in hidden_units:\n",
    "        model.add(layers.Dense(units, activation='relu'))\n",
    "\n",
    "    model.add(layers.Dense(output_units, activation='softmax'))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def train_and_evaluate_mlp(model, x_train, y_train, x_test, y_test, batch_size, epochs, verbose):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    history = model.fit(\n",
    "        x_train, y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=(x_test, y_test),\n",
    "        verbose=verbose\n",
    "    )\n",
    "\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "    train_loss, train_accuracy = model.evaluate(x_train, y_train, verbose=0)\n",
    "\n",
    "    return {\n",
    "        'train_accuracy': train_accuracy,\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'train_loss': train_loss,\n",
    "        'test_loss': test_loss,\n",
    "        'history': history,\n",
    "        'training_time': training_time\n",
    "    }\n",
    "\n",
    "def plot_training_curves(history, model_name):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Test Accuracy')\n",
    "    plt.title(f'{model_name} Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def compare_mlp_architectures(architectures, x_train, y_train, x_test, y_test, epochs, batch_size, verbose):\n",
    "    results = {}\n",
    "\n",
    "    for name, hidden_layers in architectures.items():\n",
    "        print(f\"Training {name} with architecture {hidden_layers}...\")\n",
    "\n",
    "        model = create_mlp(input_shape=x_train.shape[1],\n",
    "                           hidden_units=hidden_layers,\n",
    "                           output_units=10)\n",
    "        \n",
    "        history_info = train_and_evaluate_mlp(\n",
    "            model, x_train, y_train, x_test, y_test,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            verbose=verbose\n",
    "        )\n",
    "\n",
    "        trainable_params = np.sum([np.prod(v.shape) for v in model.trainable_weights])\n",
    "\n",
    "        results[name] = {\n",
    "            'train_accuracy': history_info['train_accuracy'],\n",
    "            'test_accuracy': history_info['test_accuracy'],\n",
    "            'parameters': trainable_params,\n",
    "            'model': model,\n",
    "            'history': history_info['history'],\n",
    "            'training_time': history_info['training_time']\n",
    "        }\n",
    "\n",
    "        print(f\"  Train accuracy: {results[name]['train_accuracy']:.4f}\")\n",
    "        print(f\"  Test accuracy: {results[name]['test_accuracy']:.4f}\")\n",
    "        print(f\"  Parameters: {results[name]['parameters']:,}\")\n",
    "        print(f\"  Training time: {results[name]['training_time']:.2f} seconds\\n\")\n",
    "        \n",
    "        plot_training_curves(history_info['history'], model_name=name)\n",
    "\n",
    "    return results\n",
    "\n",
    "def plot_mlp_comparison(results, architectures):\n",
    "    data = {\n",
    "        'MLP': [],\n",
    "        'Hidden Layers': [],\n",
    "        'Parameters': [],\n",
    "        'Train Accuracy': [],\n",
    "        'Test Accuracy': []\n",
    "    }\n",
    "\n",
    "    # Collect data for plotting\n",
    "    for name, res in results.items():\n",
    "        data['MLP'].append(name)\n",
    "        data['Hidden Layers'].append(len(architectures[name]))\n",
    "        data['Parameters'].append(res['parameters'])\n",
    "        data['Train Accuracy'].append(res['train_accuracy'])\n",
    "        data['Test Accuracy'].append(res['test_accuracy'])\n",
    "\n",
    "    sorted_indices = np.argsort(data['Hidden Layers'])\n",
    "    hidden_layers = np.array(data['Hidden Layers'])[sorted_indices]\n",
    "    parameters = np.array(data['Parameters'])[sorted_indices]\n",
    "    train_acc = np.array(data['Train Accuracy'])[sorted_indices]\n",
    "    test_acc = np.array(data['Test Accuracy'])[sorted_indices]\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Primary plot with accuracy vs hidden layers\n",
    "    ax1 = plt.gca()\n",
    "    ax1.plot(hidden_layers, train_acc, 'o-', label='Train Acc', color='blue')\n",
    "    ax1.plot(hidden_layers, test_acc, 's-', label='Test Acc', color='orange')\n",
    "    ax1.set_xlabel('Number of Hidden Layers (Increasing)')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.set_xticks(hidden_layers)  \n",
    "    ax1.grid(True)\n",
    "    ax1.legend()\n",
    "\n",
    "    # Secondary X-axis for parameter count\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.set_xlim(ax1.get_xlim())\n",
    "    ax2.set_xticks(hidden_layers)\n",
    "    \n",
    "    param_labels = [f'{p/1e6:.1f}M' for p in parameters]\n",
    "    ax2.set_xticklabels(param_labels, rotation=45)\n",
    "    ax2.set_xlabel('Number of Parameters')\n",
    "\n",
    "    plt.title('Accuracy vs Depth and Parameters')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot all test accuracies together\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for name, res in results.items():\n",
    "        plt.plot(res['history'].history['val_accuracy'], label=f\"{name} Test\")\n",
    "    plt.title('Test Accuracy Across All Architectures')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Create detailed results table\n",
    "    detailed_data = {\n",
    "        'MLP': [],\n",
    "        'Architecture': [],\n",
    "        'Hidden Layers': [],\n",
    "        'Parameters': [],\n",
    "        'Train Accuracy': [],\n",
    "        'Test Accuracy': [],\n",
    "        'Train Loss': [],\n",
    "        'Test Loss': [],\n",
    "        'Training Time (s)': []\n",
    "    }\n",
    "\n",
    "    for name, res in results.items():\n",
    "        detailed_data['MLP'].append(name)\n",
    "        detailed_data['Architecture'].append(str(architectures[name]))\n",
    "        detailed_data['Hidden Layers'].append(len(architectures[name]))\n",
    "        detailed_data['Parameters'].append(f\"{res['parameters']:,}\")\n",
    "        detailed_data['Train Accuracy'].append(f\"{res['train_accuracy']:.4f}\")\n",
    "        detailed_data['Test Accuracy'].append(f\"{res['test_accuracy']:.4f}\")\n",
    "        detailed_data['Train Loss'].append(f\"{res['history'].history['loss'][-1]:.4f}\")\n",
    "        detailed_data['Test Loss'].append(f\"{res['history'].history['val_loss'][-1]:.4f}\")\n",
    "        detailed_data['Training Time (s)'].append(f\"{res['training_time']:.2f}\")\n",
    "\n",
    "    detailed_df = pd.DataFrame(detailed_data)\n",
    "\n",
    "    return detailed_df\n",
    "\n",
    "def run_task3(mlp_architectures, epochs, batch_size=50):\n",
    "    X_train, X_test, y_train, y_test = load_mnist_data()\n",
    "\n",
    "    # Convert labels to one-hot\n",
    "    y_train_one_hot = keras.utils.to_categorical(y_train, 10)\n",
    "    y_test_one_hot = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "    # Sample subset for faster training\n",
    "    indices = np.random.choice(len(X_train), 10000, replace=False)\n",
    "    X_train = X_train[indices]\n",
    "    y_train_one_hot = y_train_one_hot[indices]\n",
    "\n",
    "    comparison_results = compare_mlp_architectures(\n",
    "        mlp_architectures,\n",
    "        X_train,\n",
    "        y_train_one_hot,\n",
    "        X_test,\n",
    "        y_test_one_hot,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    detailed_df = plot_mlp_comparison(comparison_results, mlp_architectures)\n",
    "    \n",
    "    print(\"\\nComparison of All MLP Architectures:\")\n",
    "    display(detailed_df)\n",
    "\n",
    "    return detailed_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Task 3\n",
    "\n",
    "mlp_architectures = {\n",
    "    'MLP-1': [1000, 1000],\n",
    "    'MLP-2': [1000, 1000, 1000],\n",
    "    'MLP-3': [1000, 1000, 1000, 1000, 1000],\n",
    "    'MLP-4': [500, 500, 500, 500, 500, 500, 500],\n",
    "    'MLP-5': [500, 500, 500, 500, 500, 500, 500, 500, 500]\n",
    "}\n",
    "\n",
    "mlp_df = run_task3(mlp_architectures, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4 Code\n",
    "\n",
    "def prepare_cnn_data():\n",
    "    X_train_flattened, X_test_flattened, y_train, y_test = load_mnist_data()\n",
    "\n",
    "    n_train = len(y_train)\n",
    "    n_test = len(y_test)\n",
    "\n",
    "    # Reshape from flattened back to image format and rescale to [0,1]\n",
    "    x_train = ((X_train_flattened.reshape((n_train, 28, 28, 1))) + 1) / 2\n",
    "    x_test = ((X_test_flattened.reshape((n_test, 28, 28, 1))) + 1) / 2\n",
    "\n",
    "    # One-hot encode labels\n",
    "    y_train_oh = tf.keras.utils.to_categorical(y_train, 10)\n",
    "    y_test_oh = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "    return x_train, y_train_oh, x_test, y_test_oh\n",
    "\n",
    "def create_cnn(input_shape, filters, output_units):\n",
    "    model = Sequential()\n",
    "\n",
    "    # First convolutional layer\n",
    "    model.add(Conv2D(filters[0], kernel_size=(4, 4), strides=(1, 1), padding='same', activation='relu', input_shape=input_shape))\n",
    "\n",
    "    # Subsequent convolutional layers with stride=2\n",
    "    for f in filters[1:]:\n",
    "        model.add(Conv2D(f, kernel_size=(4, 4), strides=(2, 2), padding='same', activation='relu'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(output_units, activation='softmax'))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_cnn_model(model, x_train, y_train, x_test, y_test, batch_size, epochs, verbose):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    history = model.fit(\n",
    "        x_train, y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=(x_test, y_test),\n",
    "        verbose=verbose\n",
    "    )\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "\n",
    "    train_loss, train_accuracy = model.evaluate(x_train, y_train, verbose=0)\n",
    "    test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "    return {\n",
    "        'model': model,\n",
    "        'history': history,\n",
    "        'train_accuracy': train_accuracy,\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'training_time': training_time\n",
    "    }\n",
    "\n",
    "def plot_cnn_results(history, name, architecture):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs_range = range(len(acc))\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "    plt.title(f'{name}: Accuracy - Architecture {architecture}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.title(f'{name}: Loss - Architecture {architecture}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def create_and_train_cnn(name, filters, x_train, y_train, x_test, y_test, batch_size, epochs):\n",
    "    # Clear previous models from memory\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    model = create_cnn(input_shape=x_train.shape[1:], filters=filters, output_units=10)\n",
    "    model._name = name\n",
    "    result = train_cnn_model(model, x_train, y_train, x_test, y_test, batch_size=batch_size, epochs=epochs, verbose=0)\n",
    "\n",
    "    # Count trainable parameters\n",
    "    trainable_params = np.sum([np.prod(v.shape) for v in model.trainable_weights])\n",
    "\n",
    "    result.update({\n",
    "        'name': name,\n",
    "        'parameters': trainable_params\n",
    "    })\n",
    "    return result\n",
    "\n",
    "def compare_architectures(architectures, x_train, y_train, x_test, y_test, batch_size, epochs):\n",
    "    results = {}\n",
    "    base_model = None\n",
    "    for name, filters in architectures.items():\n",
    "        print(f\"\\nTraining {name} with filters {filters} ...\")\n",
    "        results[name] = create_and_train_cnn(\n",
    "            name, filters, x_train, y_train, x_test, y_test, batch_size, epochs\n",
    "        )\n",
    "        print(f\"  -> Train accuracy: {results[name]['train_accuracy']:.4f}\")\n",
    "        print(f\"  -> Test accuracy:  {results[name]['test_accuracy']:.4f}\")\n",
    "        print(f\"  -> Parameters:    {results[name]['parameters']:,}\")\n",
    "        print(f\"  -> Training time: {results[name]['training_time']:.2f} seconds\\n\")\n",
    "        \n",
    "        plot_cnn_results(results[name]['history'], name, str(filters))\n",
    "\n",
    "        if name == 'CNN-1':\n",
    "            base_model = results[name]['model']\n",
    "\n",
    "    return results, base_model\n",
    "\n",
    "def plot_accuracy_by_model_size(results, architectures):\n",
    "    # Extract data from results\n",
    "    cnn_names = list(results.keys())\n",
    "    test_acc = [results[name]['test_accuracy'] for name in cnn_names]\n",
    "    train_acc = [results[name]['train_accuracy'] for name in cnn_names]\n",
    "    parameters = [results[name]['parameters'] for name in cnn_names]\n",
    "    training_times = [results[name]['training_time'] / 10 for name in cnn_names]  # Time per epoch\n",
    "    \n",
    "    # Sort by test accuracy (descending)\n",
    "    sorted_indices = np.argsort(test_acc)[::-1]\n",
    "    cnn_names_sorted = [cnn_names[i] for i in sorted_indices]\n",
    "    test_acc_sorted = [test_acc[i] for i in sorted_indices]\n",
    "    train_acc_sorted = [train_acc[i] for i in sorted_indices]\n",
    "    parameters_sorted = [parameters[i] for i in sorted_indices]\n",
    "    training_times_sorted = [training_times[i] for i in sorted_indices]\n",
    "    \n",
    "    # Create bubble scatter plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Calculate bubble sizes based on parameters\n",
    "    size_factor = 300\n",
    "    bubble_sizes = [p/np.max(parameters_sorted)*size_factor for p in parameters_sorted]\n",
    "    \n",
    "    scatter = plt.scatter(training_times_sorted, test_acc_sorted, s=bubble_sizes, \n",
    "                         alpha=0.7, c='blue', edgecolor='black')\n",
    "    \n",
    "    # Add model labels\n",
    "    for i, txt in enumerate(cnn_names_sorted):\n",
    "        plt.annotate(txt, (training_times_sorted[i], test_acc_sorted[i]), \n",
    "                    xytext=(5, 0), textcoords='offset points', fontsize=9)\n",
    "    \n",
    "    plt.title('CNN Model Comparison: Accuracy vs Training Time')\n",
    "    plt.xlabel('Training Time per Epoch (seconds)')\n",
    "    plt.ylabel('Test Accuracy')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.text(0.5, -0.15, \"Note: Bubble size represents number of parameters\", \n",
    "            ha=\"center\", transform=plt.gca().transAxes, fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_comparison(results, architectures):\n",
    "    results_table = {\n",
    "        'CNN': [],\n",
    "        'Architecture': [],\n",
    "        'Layers': [],\n",
    "        'Parameters': [],\n",
    "        'Train Accuracy': [],\n",
    "        'Test Accuracy': [],\n",
    "        'Training Time (s)': []\n",
    "    }\n",
    "\n",
    "    for name, result in results.items():\n",
    "        results_table['CNN'].append(name)\n",
    "        results_table['Architecture'].append(str(architectures[name]))\n",
    "        results_table['Layers'].append(len(architectures[name]))\n",
    "        results_table['Parameters'].append(result['parameters'])\n",
    "        results_table['Train Accuracy'].append(result['train_accuracy'])\n",
    "        results_table['Test Accuracy'].append(result['test_accuracy'])\n",
    "        results_table['Training Time (s)'].append(result['training_time'])\n",
    "\n",
    "    # Plot accuracy by model size\n",
    "    plot_accuracy_by_model_size(results, architectures)\n",
    "    \n",
    "    # Plot all training histories on a single plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for name in results.keys():\n",
    "        plt.plot(results[name]['history'].history['val_accuracy'], \n",
    "                 label=f\"{name} - {architectures[name]}\")\n",
    "    plt.title('Test Accuracy Across All CNN Architectures')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    summary_df = pd.DataFrame({\n",
    "        'CNN': results_table['CNN'],\n",
    "        'Architecture': results_table['Architecture'],\n",
    "        'Layers': results_table['Layers'],\n",
    "        'Parameters': [f\"{p:,}\" for p in results_table['Parameters']],\n",
    "        'Train Accuracy': [f\"{acc:.4f}\" for acc in results_table['Train Accuracy']],\n",
    "        'Test Accuracy': [f\"{acc:.4f}\" for acc in results_table['Test Accuracy']],\n",
    "        'Training Time (s)': [f\"{t:.2f}\" for t in results_table['Training Time (s)']]\n",
    "    })\n",
    "    \n",
    "    print(\"\\nCNN Architecture Comparison Summary:\")\n",
    "    display(summary_df)\n",
    "\n",
    "    return summary_df\n",
    "\n",
    "def table_mlp_cnn_comparison(df1, df2):\n",
    "    df1 = df1[['MLP', 'Test Accuracy', 'Parameters', 'Training Time (s)']]\n",
    "    df2 = df2[['CNN', 'Test Accuracy', 'Parameters', 'Training Time (s)']]\n",
    "\n",
    "    df1['Epochs'] = 20\n",
    "    df2['Epochs'] = 10\n",
    "\n",
    "    df1['Epoch Train Time (s)'] = df1['Training Time (s)'].apply(lambda x: float(x)) / df1['Epochs']\n",
    "    df2['Epoch Train Time (s)'] = df2['Training Time (s)'].apply(lambda x: float(x)) / df2['Epochs']\n",
    "\n",
    "    df1['Parameters'] = df1['Parameters'].apply(lambda x: int(x.replace(',', '')))\n",
    "    df2['Parameters'] = df2['Parameters'].apply(lambda x: int(x.replace(',', '')))\n",
    "\n",
    "    df1['Parameters'] = df1['Parameters'].apply(lambda x: f\"{x:,}\")\n",
    "    df2['Parameters'] = df2['Parameters'].apply(lambda x: f\"{x:,}\")\n",
    "\n",
    "    df1['Epoch Train Time (s) / 1m param'] = round(df1['Epoch Train Time (s)'] / (df1['Parameters'].apply(lambda x: int(x.replace(',', ''))) / 1000000), 2)\n",
    "    df2['Epoch Train Time (s) / 1m param'] = round(df2['Epoch Train Time (s)'] / (df2['Parameters'].apply(lambda x: int(x.replace(',', ''))) / 1000000), 2)\n",
    "\n",
    "    df1.rename(columns={'MLP': 'MLP Architecture', 'Test Accuracy': 'MLP Test Accuracy', 'Parameters': 'MLP Parameters', 'Training Time (s)': 'MLP Training Time (s)-MLP', 'MLP Epoch Train Time (s)': 'Epoch Train Time (s)-MLP', 'Epoch Train Time (s) / 1m param': 'MLP Epoch Train Time (s) / 1m param-MLP'}, inplace=True)\n",
    "    df2.rename(columns={'CNN': 'CNN Architecture', 'Test Accuracy': 'CNN Test Accuracy', 'Parameters': 'CNN Parameters', 'Training Time (s)': 'CNN Training Time (s)-CNN', 'CNN Epoch Train Time (s)': 'Epoch Train Time (s)-CNN', 'Epoch Train Time (s) / 1m param': 'CNN Epoch Train Time (s) / 1m param-CNN'}, inplace=True)\n",
    "\n",
    "    df = pd.concat([df1, df2], axis=1)\n",
    "\n",
    "    print(\"\\nMLP and CNN Comparison Table:\")\n",
    "    display(df)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    return df1, df2\n",
    "\n",
    "def plot_mlp_cnn_comparison(df1, df2):\n",
    "    mlp_models = df1['MLP Architecture'].tolist()\n",
    "    cnn_models = df2['CNN Architecture'].tolist()\n",
    "    mlp_accuracy = df1['MLP Test Accuracy'].astype(float).tolist()\n",
    "    cnn_accuracy = df2['CNN Test Accuracy'].astype(float).tolist()\n",
    "    mlp_params = [int(param.replace(',', '')) for param in df1['MLP Parameters'].tolist()]\n",
    "    cnn_params = [int(param.replace(',', '')) for param in df2['CNN Parameters'].tolist()]\n",
    "    mlp_epoch_time = df1['Epoch Train Time (s)'].tolist()\n",
    "    cnn_epoch_time = df2['Epoch Train Time (s)'].tolist()\n",
    "\n",
    "    # Combined plot: Efficiency and Speed comparison\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    # Left plot: Accuracy per parameter (efficiency)\n",
    "    efficiency_mlp = [acc/(param/1_000_000) for acc, param in zip(mlp_accuracy, mlp_params)]\n",
    "    efficiency_cnn = [acc/(param/1_000_000) for acc, param in zip(cnn_accuracy, cnn_params)]\n",
    "\n",
    "    x = np.arange(len(mlp_models))\n",
    "    width = 0.35\n",
    "\n",
    "    ax1.bar(x - width/2, efficiency_mlp, width, label='MLP', color='blue')\n",
    "    ax1.bar(x + width/2, efficiency_cnn, width, label='CNN', color='red')\n",
    "    ax1.set_xlabel('Model Index')\n",
    "    ax1.set_ylabel('Accuracy per Million Parameters')\n",
    "    ax1.set_title('Model Efficiency')\n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels([f'{i+1}' for i in range(len(mlp_models))])\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, axis='y', alpha=0.3)\n",
    "\n",
    "    # Right plot: Accuracy vs Training Time\n",
    "    size_factor = 300\n",
    "    mlp_size = [p/np.max(mlp_params)*size_factor for p in mlp_params]\n",
    "    cnn_size = [p/np.max(cnn_params)*size_factor for p in cnn_params]\n",
    "\n",
    "    scatter1 = ax2.scatter(mlp_epoch_time, mlp_accuracy, s=mlp_size, alpha=0.7, \n",
    "                        label='MLP', color='blue', edgecolor='black')\n",
    "    scatter2 = ax2.scatter(cnn_epoch_time, cnn_accuracy, s=cnn_size, alpha=0.7, \n",
    "                        label='CNN', color='red', edgecolor='black')\n",
    "\n",
    "    # Add model labels\n",
    "    for i, txt in enumerate(mlp_models):\n",
    "        ax2.annotate(txt, (mlp_epoch_time[i], mlp_accuracy[i]), \n",
    "                    xytext=(5, 0), textcoords='offset points', fontsize=8)\n",
    "    for i, txt in enumerate(cnn_models):\n",
    "        ax2.annotate(txt, (cnn_epoch_time[i], cnn_accuracy[i]), \n",
    "                    xytext=(5, 0), textcoords='offset points', fontsize=8)\n",
    "\n",
    "    ax2.set_xlabel('Training Time per Epoch (seconds)')\n",
    "    ax2.set_ylabel('Test Accuracy')\n",
    "    ax2.set_title('Accuracy vs Training Time')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.legend()\n",
    "\n",
    "    ax2.text(0.5, -0.2, \"Note: Marker size represents number of parameters\", \n",
    "            ha=\"center\", transform=ax2.transAxes, fontsize=8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def run_task4(cnn_architectures, epochs, batch_size=50):\n",
    "    x_train, y_train, x_test, y_test = prepare_cnn_data()\n",
    "\n",
    "    results, base_model = compare_architectures(cnn_architectures,\n",
    "                                                x_train, y_train,\n",
    "                                                x_test, y_test,\n",
    "                                                batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "    summary_df = plot_comparison(results, cnn_architectures)\n",
    "\n",
    "    return base_model, summary_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Task 4\n",
    "\n",
    "cnn_architectures = {\n",
    "    'CNN-1': [32, 64, 128],\n",
    "    'CNN-2': [64, 128],\n",
    "    'CNN-3': [128, 128, 128],\n",
    "    'CNN-4': [16, 32],\n",
    "    'CNN-5': [32, 64, 128, 256, 512]\n",
    "}\n",
    "\n",
    "base_cnn_model, cnn_df = run_task4(cnn_architectures=cnn_architectures, epochs=10)\n",
    "\n",
    "df1, df2 = table_mlp_cnn_comparison(mlp_df, cnn_df)\n",
    "\n",
    "plot_mlp_cnn_comparison(df1, df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 5 Code \n",
    "\n",
    "\n",
    "def plot_filters(model, layer_idx, cols):\n",
    "    layer = model.layers[layer_idx]\n",
    "    if not isinstance(layer, layers.Conv2D):\n",
    "        print(f\"Layer {layer_idx} is not a convolutional layer.\")\n",
    "        return\n",
    "    \n",
    "    filters, _ = layer.get_weights()\n",
    "    n_filters = filters.shape[-1]\n",
    "    rows = int(np.ceil(n_filters / cols))\n",
    "    \n",
    "    plt.figure(figsize=(cols, rows))\n",
    "    for i in range(n_filters):\n",
    "        plt.subplot(rows, cols, i + 1)\n",
    "        # Average across channels if multi-channel\n",
    "        filter_img = filters[:, :, 0, i] if filters.shape[2] == 1 else np.mean(filters[:, :, :, i], axis=2)\n",
    "        filter_img = (filter_img - filter_img.min()) / (filter_img.max() - filter_img.min() + 1e-7)\n",
    "        plt.imshow(filter_img, cmap='viridis')\n",
    "        plt.axis('off')\n",
    "        plt.title(f'{i+1}', fontsize=8)\n",
    "    plt.suptitle(f'Filters of {layer.name}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_activations(model, image, layer_indices, digit_class, cols):\n",
    "    # Add batch dimension if needed\n",
    "    if len(image.shape) == 3:\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "\n",
    "    for layer_idx in layer_indices:\n",
    "        layer = model.layers[layer_idx]\n",
    "        if not isinstance(layer, tf.keras.layers.Conv2D):\n",
    "            continue\n",
    "\n",
    "        # Create submodel to extract activations\n",
    "        input_tensor = tf.keras.Input(shape=(28, 28, 1))\n",
    "        x = input_tensor\n",
    "        for l in model.layers[:layer_idx + 1]:\n",
    "            x = l(x)\n",
    "        activation_model = tf.keras.models.Model(inputs=input_tensor, outputs=x)\n",
    "\n",
    "        activations = activation_model.predict(image, verbose=0)\n",
    "\n",
    "        n_filters = activations.shape[-1]\n",
    "        rows = int(np.ceil(n_filters / cols))\n",
    "\n",
    "        plt.figure(figsize=(cols * 2, rows * 2))\n",
    "        for i in range(n_filters):\n",
    "            plt.subplot(rows, cols, i + 1)\n",
    "            activation = activations[0, :, :, i]\n",
    "    \n",
    "            activation = (activation - activation.min()) / (activation.max() - activation.min() + 1e-7)\n",
    "            plt.imshow(activation, cmap='viridis')\n",
    "            plt.axis('off')\n",
    "            plt.title(f'Filter {i+1}')\n",
    "        plt.suptitle(f'Activations of {layer.name} for Digit {digit_class}')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def plot_deep_dream(model, class_indices, input_shape, iterations, learning_rate):\n",
    "    plt.figure(figsize=(len(class_indices) * 5, 5))\n",
    "    for i, class_idx in enumerate(class_indices):\n",
    "        # Start with random noise\n",
    "        img = tf.random.normal((1,) + input_shape) * 0.1\n",
    "        img = tf.Variable(img, dtype=tf.float32)\n",
    "        steps = iterations\n",
    "        \n",
    "        # Gradient ascent to maximise class activation\n",
    "        for _ in range(steps):\n",
    "            with tf.GradientTape() as tape:\n",
    "                pred = model(img)\n",
    "                loss = -tf.math.log(pred[0, class_idx] + 1e-7)\n",
    "            grads = tape.gradient(loss, img)\n",
    "            img.assign_sub(grads * learning_rate)\n",
    "            # Normalise periodically\n",
    "            if _ % 10 == 0:\n",
    "                img_np = img.numpy()\n",
    "                img_np = (img_np - img_np.min()) / (img_np.max() - img_np.min() + 1e-7)\n",
    "                img.assign(tf.convert_to_tensor(img_np, dtype=tf.float32))\n",
    "        \n",
    "        plt.subplot(1, len(class_indices), i + 1)\n",
    "        dream_img = np.squeeze(img.numpy())\n",
    "        plt.imshow(dream_img, cmap='viridis')\n",
    "        plt.title(f\"Deep Dream: Digit {class_idx}\")\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def run_task5(model, digit_pairs, cols=16, dream_iterations=1000, dream_learning_rate=0.001):\n",
    "    _, X_test_flatened, _, y_test = load_mnist_data()\n",
    "    \n",
    "    n_test = X_test_flatened.shape[0]\n",
    "    x_test = X_test_flatened.reshape(n_test, 28, 28, 1)\n",
    "    \n",
    "    y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "    \n",
    "    conv_layer_indices = [i for i, layer in enumerate(model.layers) if isinstance(layer, layers.Conv2D)]\n",
    "    \n",
    "    digit_classes = digit_pairs[0]\n",
    "    digit_2, digit_9 = digit_classes\n",
    "    \n",
    "    y_test_labels = np.argmax(y_test, axis=1)\n",
    "    digit_2_idx = np.where(y_test_labels == digit_2)[0][0]\n",
    "    digit_9_idx = np.where(y_test_labels == digit_9)[0][0]\n",
    "    digit_2_img = x_test[digit_2_idx]\n",
    "    digit_9_img = x_test[digit_9_idx]\n",
    "    \n",
    "    model.build((None, 28, 28, 1))\n",
    "    \n",
    "    print(\"Visualising Filters:\")\n",
    "    for layer_idx in conv_layer_indices:\n",
    "        plot_filters(model, layer_idx, 16)\n",
    "    \n",
    "    print(\"\\nVisualising Activations for Digit '2':\")\n",
    "    plot_activations(model, digit_2_img, conv_layer_indices, digit_class=2, cols=16)\n",
    "    print(\"\\nVisualising Activations for Digit '9':\")\n",
    "    plot_activations(model, digit_9_img, conv_layer_indices, digit_class=9, cols=16)\n",
    "    \n",
    "    print(\"\\nGenerating Deep Dream Images for Digits '2' and '9':\")\n",
    "    plot_deep_dream(model, class_indices=[2, 9], input_shape=(28, 28, 1), iterations=dream_iterations, learning_rate=dream_learning_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Task 5\n",
    "\n",
    "digit_pairs = [(2, 9)]\n",
    "\n",
    "run_task5(base_cnn_model, digit_pairs, dream_iterations=1000, dream_learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 6 Code\n",
    "\n",
    "def load_fashion_mnist_data():\n",
    "    (train_X, train_y_1), (test_X, test_y_1) = keras.datasets.fashion_mnist.load_data()\n",
    "    train_X = np.expand_dims(train_X / 255.0, axis=-1)  # Normalise to [0,1] and add channel\n",
    "    test_X = np.expand_dims(test_X / 255.0, axis=-1)\n",
    "\n",
    "    # Create group labels from individual item labels\n",
    "    def create_group_label(y):\n",
    "        group_labels = np.zeros_like(y)\n",
    "        group_labels[np.isin(y, [5, 7, 9])] = 0  # Shoes\n",
    "        group_labels[np.isin(y, [3, 6, 8])] = 1  # Gendered\n",
    "        group_labels[np.isin(y, [0, 1, 2, 4])] = 2  # Uni-Sex\n",
    "        return group_labels\n",
    "\n",
    "    train_y_2 = create_group_label(train_y_1)\n",
    "    test_y_2 = create_group_label(test_y_1)\n",
    "\n",
    "    train_y_1 = keras.utils.to_categorical(train_y_1, 10)\n",
    "    test_y_1 = keras.utils.to_categorical(test_y_1, 10)\n",
    "    train_y_2 = keras.utils.to_categorical(train_y_2, 3)\n",
    "    test_y_2 = keras.utils.to_categorical(test_y_2, 3)\n",
    "\n",
    "    return train_X, train_y_1, train_y_2, test_X, test_y_1, test_y_2\n",
    "\n",
    "def create_single_task_cnn(input_shape, num_classes, task_name):\n",
    "    model = models.Sequential(name=f\"Single_{task_name}\")\n",
    "    model.add(layers.Conv2D(32, kernel_size=3, strides=1, padding='same', activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling2D(pool_size=2, strides=2))\n",
    "    model.add(layers.Conv2D(64, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=2, strides=2))\n",
    "    model.add(layers.Conv2D(128, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(3136, activation='relu'))\n",
    "    model.add(layers.Dense(1024, activation='relu'))\n",
    "    model.add(layers.Dense(100, activation='relu'))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def create_multitask_model(input_shape, lambda_value):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(32, kernel_size=3, strides=1, padding='same', activation='relu')(inputs)\n",
    "    x = layers.MaxPooling2D(pool_size=2, strides=2)(x)\n",
    "    x = layers.Conv2D(64, kernel_size=3, strides=1, padding='same', activation='relu')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2, strides=2)(x)\n",
    "    x = layers.Conv2D(128, kernel_size=3, strides=1, padding='same', activation='relu')(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    shared_dense = layers.Dense(3136, activation='relu')(x)\n",
    "\n",
    "    # Item classification\n",
    "    task1 = layers.Dense(1024, activation='relu')(shared_dense)\n",
    "    task1 = layers.Dense(100, activation='relu')(task1)\n",
    "    task1_output = layers.Dense(10, activation='softmax', name='task1_output')(task1)\n",
    "\n",
    "    # Group classification\n",
    "    task2 = layers.Dense(1024, activation='relu')(shared_dense)\n",
    "    task2 = layers.Dense(100, activation='relu')(task2)\n",
    "    task2_output = layers.Dense(3, activation='softmax', name='task2_output')(task2)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=[task1_output, task2_output])\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss={'task1_output': 'categorical_crossentropy', 'task2_output': 'categorical_crossentropy'},\n",
    "                  loss_weights={'task1_output': float(lambda_value), 'task2_output': 1.0 - float(lambda_value)},\n",
    "                  metrics={'task1_output': 'accuracy', 'task2_output': 'accuracy'})\n",
    "    return model\n",
    "\n",
    "def plot_training_history(history, model_name):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Accuracy plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    if 'accuracy' in history.history:\n",
    "        plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "        plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    else:\n",
    "        plt.plot(history.history['task1_output_accuracy'], label='Task1 Train Acc')\n",
    "        plt.plot(history.history['task2_output_accuracy'], label='Task2 Train Acc')\n",
    "        plt.plot(history.history['val_task1_output_accuracy'], label='Task1 Val Acc')\n",
    "        plt.plot(history.history['val_task2_output_accuracy'], label='Task2 Val Acc')\n",
    "    \n",
    "    plt.title(f'{model_name} - Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Loss plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    if 'loss' in history.history:\n",
    "        plt.plot(history.history['loss'], label='Train Loss')\n",
    "        plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    else:\n",
    "        plt.plot(history.history['task1_output_loss'], label='Task1 Train Loss')\n",
    "        plt.plot(history.history['task2_output_loss'], label='Task2 Train Loss')\n",
    "        plt.plot(history.history['val_task1_output_loss'], label='Task1 Val Loss')\n",
    "        plt.plot(history.history['val_task2_output_loss'], label='Task2 Val Loss')\n",
    "    \n",
    "    plt.title(f'{model_name} - Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def train_single_task_models(train_X, train_y_1, train_y_2, test_X, test_y_1, test_y_2, batch_size, epochs):\n",
    "    model_task1 = create_single_task_cnn(train_X.shape[1:], 10, \"Task1_Item\")\n",
    "    model_task2 = create_single_task_cnn(train_X.shape[1:], 3, \"Task2_Group\")\n",
    "\n",
    "    print(\"\\nTraining Item Classification Model...\")\n",
    "    start_time = time.time()\n",
    "    history_task1 = model_task1.fit(train_X, train_y_1, batch_size=batch_size, epochs=epochs, validation_data=(test_X, test_y_1), verbose=0)\n",
    "    task1_train_time = time.time() - start_time\n",
    "    task1_test_loss, task1_test_acc = model_task1.evaluate(test_X, test_y_1, verbose=0)\n",
    "    print(f\"Item Classification - Test Accuracy: {task1_test_acc:.4f}\")\n",
    "    \n",
    "    plot_training_history(history_task1, \"Single Task - Item Classification\")\n",
    "\n",
    "    print(\"\\nTraining Group Classification Model...\")\n",
    "    start_time = time.time()\n",
    "    history_task2 = model_task2.fit(train_X, train_y_2, batch_size=batch_size, epochs=epochs,\n",
    "                                    validation_data=(test_X, test_y_2), verbose=0)\n",
    "    task2_train_time = time.time() - start_time\n",
    "    task2_test_loss, task2_test_acc = model_task2.evaluate(test_X, test_y_2, verbose=0)\n",
    "    print(f\"Group Classification - Test Accuracy: {task2_test_acc:.4f}\")\n",
    "    \n",
    "    plot_training_history(history_task2, \"Single Task - Group Classification\")\n",
    "\n",
    "    return {\n",
    "        'task1': {\n",
    "            'model': model_task1, \n",
    "            'accuracy': task1_test_acc, \n",
    "            'params': model_task1.count_params(), \n",
    "            'train_time': task1_train_time,\n",
    "            'history': history_task1\n",
    "        },\n",
    "        'task2': {\n",
    "            'model': model_task2, \n",
    "            'accuracy': task2_test_acc, \n",
    "            'params': model_task2.count_params(), \n",
    "            'train_time': task2_train_time,\n",
    "            'history': history_task2\n",
    "        }\n",
    "    }\n",
    "\n",
    "def train_multitask_models(train_X, train_y_1, train_y_2, test_X, test_y_1, test_y_2, lambda_values, batch_size, epochs):\n",
    "    mtl_results = {}\n",
    "    print(\"\\nTraining MTL Models with different  values...\")\n",
    "    for lam in lambda_values:\n",
    "        model = create_multitask_model(train_X.shape[1:], lam)\n",
    "\n",
    "        start_time = time.time()\n",
    "        history = model.fit(\n",
    "            train_X, \n",
    "            {'task1_output': train_y_1, 'task2_output': train_y_2},\n",
    "            batch_size=batch_size, \n",
    "            epochs=epochs,\n",
    "            validation_data=(test_X, {'task1_output': test_y_1, 'task2_output': test_y_2}), \n",
    "            verbose=0\n",
    "        )\n",
    "        train_time = time.time() - start_time\n",
    "\n",
    "        test_results = model.evaluate(\n",
    "            test_X, \n",
    "            {'task1_output': test_y_1, 'task2_output': test_y_2},\n",
    "            verbose=0, \n",
    "            return_dict=True\n",
    "        )\n",
    "        task1_acc = test_results.get('task1_output_accuracy', 0.0)\n",
    "        task2_acc = test_results.get('task2_output_accuracy', 0.0)\n",
    "        print(f\" = {lam}: Task 1 Acc = {task1_acc:.4f}, Task 2 Acc = {task2_acc:.4f}\")\n",
    "        \n",
    "        plot_training_history(history, f\"Multi-Task Learning (={lam})\")\n",
    "\n",
    "        mtl_results[lam] = {\n",
    "            'model': model, \n",
    "            'task1_accuracy': task1_acc, \n",
    "            'task2_accuracy': task2_acc,\n",
    "            'params': model.count_params(), \n",
    "            'train_time': train_time,\n",
    "            'history': history\n",
    "        }\n",
    "    return mtl_results\n",
    "\n",
    "def analyse_results(single_results, mtl_results, lambda_values):\n",
    "    task1_mtl_accs = [mtl_results[lam]['task1_accuracy'] for lam in lambda_values]\n",
    "    task2_mtl_accs = [mtl_results[lam]['task2_accuracy'] for lam in lambda_values]\n",
    "    single_task1_acc = single_results['task1']['accuracy']\n",
    "    single_task2_acc = single_results['task2']['accuracy']\n",
    "\n",
    "    # Plot accuracies vs lambda\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.plot(lambda_values, task1_mtl_accs, 'o-', linewidth=2, label='MTL Task 1 (Item)')\n",
    "    plt.plot(lambda_values, task2_mtl_accs, 's-', linewidth=2, label='MTL Task 2 (Group)')\n",
    "    plt.axhline(single_task1_acc, color='r', linestyle='--', linewidth=2, label=f'Single Task 1: {single_task1_acc:.4f}')\n",
    "    plt.axhline(single_task2_acc, color='g', linestyle='--', linewidth=2, label=f'Single Task 2: {single_task2_acc:.4f}')\n",
    "    plt.xlabel(' (Task 1 Loss Weight)', fontsize=12)\n",
    "    plt.ylabel('Test Accuracy', fontsize=12)\n",
    "    plt.title('MTL Performance vs. ', fontsize=14)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.xticks(lambda_values)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Model comparison bar chart\n",
    "    models = ['Single Task 1', 'Single Task 2'] + [f'MTL ={lam}' for lam in lambda_values]\n",
    "    task1_accs = [single_task1_acc, 0] + task1_mtl_accs\n",
    "    task2_accs = [0, single_task2_acc] + task2_mtl_accs\n",
    "    \n",
    "    x = np.arange(len(models))\n",
    "    width = 0.35\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    rects1 = ax.bar(x - width/2, task1_accs, width, label='Task 1 (Item) Accuracy', color='skyblue')\n",
    "    rects2 = ax.bar(x + width/2, task2_accs, width, label='Task 2 (Group) Accuracy', color='lightgreen')\n",
    "    \n",
    "    ax.set_ylabel('Test Accuracy', fontsize=12)\n",
    "    ax.set_title('Model Performance Comparison', fontsize=14)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(models, rotation=45, ha='right')\n",
    "    ax.legend(fontsize=12)\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add accuracy values on top of bars\n",
    "    def autolabel(rects):\n",
    "        for rect in rects:\n",
    "            height = rect.get_height()\n",
    "            if height > 0:\n",
    "                ax.annotate(f'{height:.4f}',\n",
    "                            xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                            xytext=(0, 3),\n",
    "                            textcoords=\"offset points\",\n",
    "                            ha='center', va='bottom')\n",
    "    \n",
    "    autolabel(rects1)\n",
    "    autolabel(rects2)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Create a pandas DataFrame for better display\n",
    "    data = {\n",
    "        'Model': ['Single Task 1', 'Single Task 2', 'Single Total'] + [f'MTL ={lam}' for lam in lambda_values],\n",
    "        'Task 1 Accuracy': [single_task1_acc, 0, 0] + [mtl_results[lam]['task1_accuracy'] for lam in lambda_values],\n",
    "        'Task 2 Accuracy': [0, single_task2_acc, 0] + [mtl_results[lam]['task2_accuracy'] for lam in lambda_values],\n",
    "        'Parameters': [single_results['task1']['params'], single_results['task2']['params'], \n",
    "                      single_results['task1']['params'] + single_results['task2']['params']] + \n",
    "                     [mtl_results[lam]['params'] for lam in lambda_values],\n",
    "        'Training Time (s)': [int(single_results['task1']['train_time']), \n",
    "                             int(single_results['task2']['train_time']), \n",
    "                             int(single_results['task1']['train_time'] + single_results['task2']['train_time'])] + \n",
    "                            [int(mtl_results[lam]['train_time']) for lam in lambda_values]\n",
    "    }\n",
    "    \n",
    "    summary_df = pd.DataFrame(data)\n",
    "    \n",
    "    summary_df['Parameters'] = summary_df['Parameters'].apply(lambda x: f\"{x:,}\")\n",
    "    \n",
    "    display(summary_df)\n",
    "\n",
    "    # Calculate parameter savings with MTL\n",
    "    param_savings = single_results['task1']['params'] + single_results['task2']['params'] - mtl_results[0.5]['params']\n",
    "    print(f\"Parameter Savings with MTL: {param_savings:,} ({param_savings/(single_results['task1']['params'] + single_results['task2']['params'])*100:.2f}%)\")\n",
    "\n",
    "    best_lambda = max(lambda_values, key=lambda lam: (mtl_results[lam]['task1_accuracy'] + mtl_results[lam]['task2_accuracy']) / 2)\n",
    "    best_avg_acc = (mtl_results[best_lambda]['task1_accuracy'] + mtl_results[best_lambda]['task2_accuracy']) / 2\n",
    "    single_avg_acc = (single_task1_acc + single_task2_acc) / 2\n",
    "    print(f\"Best MTL Avg Accuracy (={best_lambda}): {best_avg_acc:.4f} vs. Single Avg: {single_avg_acc:.4f}\")\n",
    "\n",
    "    improves_both = any(mtl_results[lam]['task1_accuracy'] > single_task1_acc and\n",
    "                        mtl_results[lam]['task2_accuracy'] > single_task2_acc for lam in lambda_values)\n",
    "    print(f\"MTL Improves Both Tasks Simultaneously: {'Yes' if improves_both else 'No'}\")\n",
    "\n",
    "def run_task6(lambda_values, epochs, batch_size=50):\n",
    "    \n",
    "    train_X, train_y_1, train_y_2, test_X, test_y_1, test_y_2 = load_fashion_mnist_data()\n",
    "\n",
    "    single_results = train_single_task_models(\n",
    "        train_X, train_y_1, train_y_2, \n",
    "        test_X, test_y_1, test_y_2, \n",
    "        batch_size=batch_size, \n",
    "        epochs=epochs\n",
    "    )\n",
    "\n",
    "    mtl_results = train_multitask_models(\n",
    "        train_X, train_y_1, train_y_2, \n",
    "        test_X, test_y_1, test_y_2,\n",
    "        lambda_values=lambda_values, \n",
    "        batch_size=batch_size, \n",
    "        epochs=epochs\n",
    "    )\n",
    "\n",
    "    analyse_results(single_results, mtl_results, lambda_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Task 6\n",
    "\n",
    "lambda_values = [0.0, 0.25, 0.5, 0.75, 1.0]\n",
    "\n",
    "run_task6(lambda_values, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc-ai-yPHgmFUp-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
