{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applications of Artificial Intelligence\n",
    "## Large Data Sets\n",
    "### Indexing\n",
    "In the previous demo you saw we could go through a large dataset in chunks. This time we'll show how we can leverage some of the material you learned last week about databases to work with various subsets of a large dataset efficiently.\n",
    "\n",
    "We'll also introduce a new library on top of SQLite called SQLAlchemy. SQLAlchemy's primary focus is providing a layer of abstraction that allows you to write classes which can be stored in and retrieved from databases directly, without having to write SQL. But it is also the main way to interface with a database from Pandas, especially if you want to use Pandas with a database other than SQLite.\n",
    "\n",
    "SQLAlchemy provides a really helpful interface between SQLite, which manages the database itself, and Pandas, which is obviously useful for doing data analysis within a single application, and actually reading CSV files in chunks. SQLAlchemy should be installed by default if you installed Python via Anaconda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "\n",
    "database = sqlalchemy.create_engine('sqlite:///database.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above creates the SQLite database via SQLAlchemy, or connects if it already exists.\n",
    "\n",
    "Now, to populate the database, we are going to read the CSV file in chunks in the same way that we did previously, inserting the data from those chunks to the database. This can be quite slow, but only needs to be done once on a large dataset. Note that we have to rename any columns from the CSV file that contain spaces, since this is not supported in the database.\n",
    "\n",
    "*Note: the code below may take a couple of minutes to run.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 93.5 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.process_time()\n",
    "\n",
    "for df in pd.read_csv('data.csv', iterator=True, chunksize=100000):\n",
    "    df = df.rename(columns={c: c.replace(' ', '_') for c in df.columns})\n",
    "    df.to_sql('Sales', database, if_exists='append')\n",
    "    \n",
    "end_time = time.process_time()\n",
    "print(f\"Total time: {end_time-start_time:.1f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas automatically set up and executed the SQL for us to store all of this data in the SQLite database. \n",
    "\n",
    "If we're curious, we can query the metadata of this table using a PRAGMA statement, to see the names of the columns, their types, and so on. This is quite a niche thing to want to do, and in reality you would probably just continue using this data via Pandas. But, just to show you what it has set up for us, you can see the result below. Notice it has had a good guess at the types of each of the columns.\n",
    "\n",
    "(You can read more about this kind of meta-SQL [here](https://www.sqlitetutorial.net/sqlite-tutorial/sqlite-describe-table/).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cid: 0, name: index, type: BIGINT, notnull: 0, dflt_value: None, pk: 0\n",
      "cid: 1, name: Region, type: TEXT, notnull: 0, dflt_value: None, pk: 0\n",
      "cid: 2, name: Country, type: TEXT, notnull: 0, dflt_value: None, pk: 0\n",
      "cid: 3, name: Item_Type, type: TEXT, notnull: 0, dflt_value: None, pk: 0\n",
      "cid: 4, name: Sales_Channel, type: TEXT, notnull: 0, dflt_value: None, pk: 0\n",
      "cid: 5, name: Order_Priority, type: TEXT, notnull: 0, dflt_value: None, pk: 0\n",
      "cid: 6, name: Order_Date, type: TEXT, notnull: 0, dflt_value: None, pk: 0\n",
      "cid: 7, name: Order_ID, type: BIGINT, notnull: 0, dflt_value: None, pk: 0\n",
      "cid: 8, name: Ship_Date, type: TEXT, notnull: 0, dflt_value: None, pk: 0\n",
      "cid: 9, name: Units_Sold, type: BIGINT, notnull: 0, dflt_value: None, pk: 0\n",
      "cid: 10, name: Unit_Price, type: FLOAT, notnull: 0, dflt_value: None, pk: 0\n",
      "cid: 11, name: Unit_Cost, type: FLOAT, notnull: 0, dflt_value: None, pk: 0\n",
      "cid: 12, name: Total_Revenue, type: FLOAT, notnull: 0, dflt_value: None, pk: 0\n",
      "cid: 13, name: Total_Cost, type: FLOAT, notnull: 0, dflt_value: None, pk: 0\n",
      "cid: 14, name: Total_Profit, type: FLOAT, notnull: 0, dflt_value: None, pk: 0\n"
     ]
    }
   ],
   "source": [
    "result = database.execute(\"PRAGMA TABLE_INFO('Sales');\")\n",
    "for row in result:\n",
    "    print(\", \".join(f\"{key}: {item}\" for key, item in row.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can manually run SELECT queries against the underlying SQLite database too. We could pick out some data in the middle of the original dataset (with index over 1 million) to confirm that it seems to be loading correctly, as shown in the cell below.\n",
    "\n",
    "We can do this because Pandas automatically inserted its own row indices as a column called `index` into our table. Since this gives each row a unique value, it would be a good candidate for a primary key if we needed one (although it did not set this up). `index` is actually a bad name for a column because it already exists as a keyword in SQL, so to query it, we have to put square brackets around the name `[index]`. We also use LIMIT to just pull a few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 1000001, Region: Europe\n",
      "index: 1000002, Region: Asia\n",
      "index: 1000003, Region: Sub-Saharan Africa\n",
      "index: 1000004, Region: Europe\n",
      "index: 1000005, Region: Sub-Saharan Africa\n"
     ]
    }
   ],
   "source": [
    "result = database.execute(\"\"\"SELECT [index], Region \n",
    "                             FROM Sales \n",
    "                             WHERE [index] > 1000000 \n",
    "                             LIMIT 5;\"\"\")\n",
    "\n",
    "for row in result:\n",
    "    print(\", \".join(f\"{key}: {item}\" for key, item in row.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if we want to do some data analysis on a subset of this data, then we will probably want the result back in a Pandas dataframe. We can pass the SQL query straight into Pandas to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 0.8 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.process_time()\n",
    "\n",
    "df = pd.read_sql_query('SELECT * FROM Sales WHERE Country=\"Oman\";', database)\n",
    "\n",
    "end_time = time.process_time()\n",
    "\n",
    "print(f\"Total time: {end_time-start_time:.1f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sales in Oman: 26996\n",
      "Preview of first three rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Region</th>\n",
       "      <th>Country</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Sales_Channel</th>\n",
       "      <th>Order_Priority</th>\n",
       "      <th>Order_Date</th>\n",
       "      <th>Order_ID</th>\n",
       "      <th>Ship_Date</th>\n",
       "      <th>Units_Sold</th>\n",
       "      <th>Unit_Price</th>\n",
       "      <th>Unit_Cost</th>\n",
       "      <th>Total_Revenue</th>\n",
       "      <th>Total_Cost</th>\n",
       "      <th>Total_Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Middle East and North Africa</td>\n",
       "      <td>Oman</td>\n",
       "      <td>Cereal</td>\n",
       "      <td>Offline</td>\n",
       "      <td>H</td>\n",
       "      <td>4/26/2019</td>\n",
       "      <td>970755660</td>\n",
       "      <td>6/2/2019</td>\n",
       "      <td>7027</td>\n",
       "      <td>205.70</td>\n",
       "      <td>117.11</td>\n",
       "      <td>1445453.9</td>\n",
       "      <td>822931.97</td>\n",
       "      <td>622521.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>Middle East and North Africa</td>\n",
       "      <td>Oman</td>\n",
       "      <td>Cosmetics</td>\n",
       "      <td>Offline</td>\n",
       "      <td>M</td>\n",
       "      <td>8/1/2016</td>\n",
       "      <td>480795896</td>\n",
       "      <td>9/10/2016</td>\n",
       "      <td>7045</td>\n",
       "      <td>437.20</td>\n",
       "      <td>263.33</td>\n",
       "      <td>3080074.0</td>\n",
       "      <td>1855159.85</td>\n",
       "      <td>1224914.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31</td>\n",
       "      <td>Middle East and North Africa</td>\n",
       "      <td>Oman</td>\n",
       "      <td>Vegetables</td>\n",
       "      <td>Online</td>\n",
       "      <td>L</td>\n",
       "      <td>6/2/2012</td>\n",
       "      <td>697118413</td>\n",
       "      <td>7/16/2012</td>\n",
       "      <td>1685</td>\n",
       "      <td>154.06</td>\n",
       "      <td>90.93</td>\n",
       "      <td>259591.1</td>\n",
       "      <td>153217.05</td>\n",
       "      <td>106374.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                        Region Country   Item_Type Sales_Channel  \\\n",
       "0      4  Middle East and North Africa    Oman      Cereal       Offline   \n",
       "1     27  Middle East and North Africa    Oman   Cosmetics       Offline   \n",
       "2     31  Middle East and North Africa    Oman  Vegetables        Online   \n",
       "\n",
       "  Order_Priority Order_Date   Order_ID  Ship_Date  Units_Sold  Unit_Price  \\\n",
       "0              H  4/26/2019  970755660   6/2/2019        7027      205.70   \n",
       "1              M   8/1/2016  480795896  9/10/2016        7045      437.20   \n",
       "2              L   6/2/2012  697118413  7/16/2012        1685      154.06   \n",
       "\n",
       "   Unit_Cost  Total_Revenue  Total_Cost  Total_Profit  \n",
       "0     117.11      1445453.9   822931.97     622521.93  \n",
       "1     263.33      3080074.0  1855159.85    1224914.15  \n",
       "2      90.93       259591.1   153217.05     106374.05  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preview all rows that have country Oman\n",
    "print(f\"Number of sales in Oman: {df.shape[0]}\")\n",
    "print(\"Preview of first three rows:\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just by using SQLite we are able to query this massive dataset in a reasonable amount of time. Database management systems do a lot of work by default to try to make queries fast, which may include some amount of indexing.\n",
    "\n",
    "But if we know we're going to be doing lots of queries that include the Country column, we can tell the database to specifically create an index on this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "database.execute(\"CREATE INDEX idx_country ON Sales (Country);\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can try the query again that pulls all the data from Oman."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 0.2 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.process_time()\n",
    "\n",
    "df = pd.read_sql_query('SELECT * FROM Sales WHERE Country=\"Oman\";', database)\n",
    "\n",
    "end_time = time.process_time()\n",
    "\n",
    "print(f\"Total time: {end_time-start_time:.1f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my test, the time went from 0.8 to 0.2 seconds, cutting the query time to 25% of its original. This could make a big difference in a data intensive operation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
