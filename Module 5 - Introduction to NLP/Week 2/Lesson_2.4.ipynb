{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2, Lesson 4, Activity 9: End-to-end IR application\n",
    "\n",
    "&copy;2021, Ekaterina Kochmar \\\n",
    "(edited: Nadejda Roubtsova, June 2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task in this activity is to:\n",
    "\n",
    "- To implement all the steps discussed in the lecture and apply your IR algorithm to the collection of documents and the set of queries provided with this notebook.\n",
    "\n",
    "Note that we continue working on the same data, so we will rely on the implementation of the previous steps (Steps 1–3) from Lesson 2.3. In this notebook, you need to start with Step 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Read in the data (same as before)\n",
    "\n",
    "There are three components to this data to be read in:\n",
    "- documents with their ids and content – there are $1460$ of those to be precise;\n",
    "- questions / queries with their ids and content – there are $112$ of those;\n",
    "- mapping between the queries and relevant documents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert relevant code cells from the notebook from Lesson 2.3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Preprocess the data (same as before)\n",
    "\n",
    "Practise application of the following steps:\n",
    "- tokenize the texts\n",
    "- put all to lowercase\n",
    "- remove stopwords\n",
    "- apply stemming\n",
    "\n",
    "Implement and apply these steps to a sample text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert relevant code cells from the notebook from Lesson 2.3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Term weighting (same as before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert relevant code cells from the notebook from Lesson 2.3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Retrieval of the most similar documents\n",
    "\n",
    "Use cosine similarity on a toy example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "query = [1, 1]\n",
    "document = [3, 5]\n",
    "\n",
    "def length(vector):\n",
    "    sq_length = 0\n",
    "    # calculate vector length\n",
    "    return math.sqrt(sq_length)\n",
    "    \n",
    "def dot_product(vector1, vector2):\n",
    "    if len(vector1)==len(vector2):\n",
    "        dot_prod = 0\n",
    "        # calculate dot product\n",
    "        return dot_prod\n",
    "    else:\n",
    "        return \"Unmatching dimensionality\"\n",
    "\n",
    "def calculate_cosine(query, document):\n",
    "    cosine =  # dot product / lengths of vectors multiplied\n",
    "    return cosine\n",
    "\n",
    "cosine = calculate_cosine(query, document)\n",
    "print (cosine) # the result should be ~0.97"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get cosine similarity for some examples of a particular query and a particular document from the collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = doc_vectors.get(\"60\")\n",
    "query = qry_vectors.get(\"3\")\n",
    "\n",
    "cosine =  # as above  \n",
    "print(cosine) # the result should be ~0.22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Document and query weighting schemes:**\n",
    "In the implementation of Lesson 2.3 (if you copied all the cells from Step 3), you may have noticed that the documents are not weighted in the same way as the queries. This is not uncommon. More information on the practice and different weighting schemes can be found in: \n",
    "Christopher D. Manning  *et.al*, *Introduction to Information Retrieval*, Cambridge University Press. 2008. \\\n",
    "https://nlp.stanford.edu/IR-book/pdf/06vect.pdf (Section 6.4.3) \\\n",
    "Please feel free to experiment with alternative weighting schemes for query and document vectors as part of these exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the search algorithm to find relevant documents for a particular query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "results = {}\n",
    "\n",
    "for doc_id in doc_vectors.keys():\n",
    "    document = doc_vectors.get(doc_id)\n",
    "    cosine = calculate_cosine(query, document)    \n",
    "    results[doc_id] = cosine\n",
    "\n",
    "for items in # print out the top 10 most similar documents according to consine similarity\n",
    "    print(f\"Doc {items[0]} with similarity {round(items[1], 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Evaluation\n",
    "\n",
    "**Optional**: Implement evaluation metrics from Lesson 5 (see Activity 11)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
