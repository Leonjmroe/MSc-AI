{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 4, Lesson 3, Activity 5: End-to-end sentiment analysis\n",
    "\n",
    "&copy;2021, Ekaterina Kochmar \\\n",
    "(edited: Nadejda Roubtsova, February 2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task in this activity is to:\n",
    "\n",
    "- Implement a sentiment analysis algorithm and train it on the set of reviews provided with the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Data loading\n",
    "\n",
    "We will be using popular `polarity dataset 2.0` collected by [Bo Pang and colleagues from Cornell Univeristy](http://www.cs.cornell.edu/people/pabo/movie-review-data/). Let's first upload the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, codecs\n",
    "\n",
    "def read_in(folder):\n",
    "    files = os.listdir(folder)\n",
    "    a_dict = {}\n",
    "    for a_file in sorted(files):\n",
    "        if not a_file.startswith(\".\"):\n",
    "            with codecs.open(folder + a_file, encoding='ISO-8859-1', errors ='ignore') as f:\n",
    "                file_id = a_file.split(\".\")[0].strip()\n",
    "                a_dict[file_id] = f.read()\n",
    "            f.close()\n",
    "    return a_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you download the dataset, it comes as two subfolders named `pos/` for all positive reviews and `neg/` for all negative ones, put within a folder called `review_polarity/txt_sentoken/`. If you don't change the folder names, you can simply read in the contents of all positive and negative reviews and put them in separate Python dictionaries of review titles mapped to the reviews content, using the method `read_in` from above.\n",
    "\n",
    "Let's also print out the number of reviews in positive and negative dictionaries, as well as the very first positive and very first negative reviews in the dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"review_polarity/txt_sentoken/\"\n",
    "pos_dict = read_in(# provide the relative path to the positive reviews folder\n",
    "                   )\n",
    "print(f\"Number of positive sentiment reviews: {len(pos_dict)}\") # check that this is 1000\n",
    "print(pos_dict.get(next(iter(pos_dict))))\n",
    "\n",
    "neg_dict = read_in(# provide the relative path to the negative reviews folder\n",
    "                   )\n",
    "print(f\"Number of positive sentiment reviews: {len(neg_dict)}\") # check that this is 1000\n",
    "print(neg_dict.get(next(iter(neg_dict))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Preprocess texts with spaCy\n",
    "\n",
    "Import `spacy`; since processing with `spacy` might take time, let's run it once and store the results in dedicated data structures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "def spacy_preprocess_reviews(source):\n",
    "    source_docs = {}\n",
    "    index = 0\n",
    "    for review_id in source.keys():\n",
    "        #to speed processing up, you can disable \"ner\" â€“ Named Entity Recognition module of spaCy\n",
    "        source_docs[review_id] = nlp(source.get(review_id).replace(\"\\n\", \"\"), disable=[\"ner\"])\n",
    "        if index>0 and (index%200)==0:\n",
    "            print(str(index) + \" reviews processed\")\n",
    "        index += 1\n",
    "    print(\"Dataset processed\")\n",
    "    return source_docs\n",
    "\n",
    "pos_docs = # preprocess positive reviews with spacy_preprocess_reviews\n",
    "neg_docs = # preprocess negative reviews with spacy_preprocess_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Apply a machine learning classifier to the data\n",
    "\n",
    "First, let's filter out punctuation marks (you can experiment by adding any other filters if you'd like e.g. stopwords) and prepare the data for the machine learning pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "#from spacy.lang.en.stop_words import STOP_WORDS as stopwords_list # stopwords list\n",
    "punctuation_list = [punct for punct in string.punctuation]\n",
    "\n",
    "def text_filter(a_dict, label, exclude_lists):\n",
    "    data = []\n",
    "    for rev_id in a_dict.keys():\n",
    "        tokens = []\n",
    "        for token in a_dict.get(rev_id):\n",
    "            if not token.text in exclude_lists:\n",
    "                # append token's text to the list of tokens\n",
    "                # Alternatively, use tokens.append(token.lemma_) for lemmas instead of word tokens\n",
    "        data.append((' '.join(tokens), label))\n",
    "    return data\n",
    "\n",
    "def prepare_data(pos_docs, neg_docs, exclude_lists):\n",
    "    data = text_filter(pos_docs, 1, exclude_lists)\n",
    "    data += text_filter(neg_docs, -1, exclude_lists)\n",
    "    random.seed(42)\n",
    "    random.shuffle(data)\n",
    "    texts = []\n",
    "    labels = []\n",
    "    for item in data:\n",
    "        # append the first entry from the tuple to texts (this is the tokens from the review)\n",
    "        # append the second entry from the tuple to labels (this is the labels: 1 for pos or -1 for neg)\n",
    "    return texts, labels\n",
    "\n",
    "# for the use of both lists in filtering:\n",
    "# texts, labels = prepare_data(pos_docs, neg_docs, list(stopwords_list) + punctuation_list)\n",
    "\n",
    "texts, labels = prepare_data(# insert the relevant data structures here\n",
    "                             ) \n",
    "\n",
    "print(f\"Total number of reviews = {len(texts)} and labels = {len(labels)}\") # there should be 2000 texts and 2000 labels\n",
    "print(texts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's prepare $80\\%$ of the data for training and rest for testing in this randomly shuffled set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(texts, labels, proportion):\n",
    "    train_data = []\n",
    "    train_targets = []\n",
    "    test_data = []\n",
    "    test_targets = []\n",
    "    for i in range(0, len(texts)):\n",
    "        if i < proportion*len(texts):\n",
    "            train_data.append(texts[i])\n",
    "            train_targets.append(labels[i])\n",
    "        else:\n",
    "            # apply the same steps to the test set data structures\n",
    "    return train_data, train_targets, test_data, test_targets\n",
    "\n",
    "train_data, train_targets, test_data, test_targets = split(texts, labels, 0.8)\n",
    "        \n",
    "print(len(train_data)) # is this 1600?\n",
    "print(len(train_targets)) # is this 1600?      \n",
    "print(len(test_data)) # is this 400?       \n",
    "print(len(test_targets)) # is this 400? \n",
    "print(train_targets[:10]) # print out the targets for the first 10 training reviews \n",
    "print(test_targets[:10]) # print out the targets for the first 10 test reviews "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's estimate the distribution of words across texts using `sklearn`'s `CountVectorizer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "train_counts = count_vect.fit_transform(train_data)\n",
    "# Check the dimensionality \n",
    "print(train_counts.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that our training set contains over $35,000$ distinct words (the exact number may change depending on your split). This is our training set vocabulary, and it will be applied to all test reviews only. Note that this vocabulary is learned on the training data only. Let's look 'under the hood' and print out the counts for some words in the first $10$ reviews from the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_counts[:11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do the results like (0, 5285)\t5 and (0, 30800)\t1 mean? \\\n",
    "The first review (index 0, a positive review since it has label `1` in `train_targets`) contains $5$ occurrences of some word with an index $5285$ and $1$ occurrences of a word with an index $30800$ from the vocabulary. Let's see what those indexes correspond to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect.get_feature_names_out()[5285]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect.get_feature_names_out()[30800]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E.g., you might find out that index $5285$ corresponds to the word *characters* and index $30800$ to the word *stuck*.  \\\n",
    "(Please note that you will get different words if you experimented with alternative preprocessing.) \\\n",
    "Here is how you can check the whole list of words (features) mapped to indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, to print the vocabulary of features in the alphabetical order run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's convert word occurrences into binary values: use $1$ if the word occurs in a reivew, and $0$ otherwise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "transformer = Binarizer()\n",
    "train_bin = transformer.fit_transform(train_counts)\n",
    "print(train_bin.shape)\n",
    "print(train_bin[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's train the classifier and run it on the designated test set: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB().fit(train_counts, train_targets)\n",
    "test_counts = count_vect.transform(test_data)\n",
    "predicted = clf.predict(test_counts)\n",
    "\n",
    "for text, label in list(zip(test_data, predicted))[:10]:\n",
    "    if label==1:\n",
    "        print('%r => %s' % (text[:100], \"pos\"))\n",
    "    else:\n",
    "        # print out the negative label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, this is how you can do the same using `sklearn`'s pipeline: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer(min_df=10, max_df=0.5)), \n",
    "                     ('binarizer', Binarizer()), # include this for detecting presence-absence of features\n",
    "                     ('clf', MultinomialNB())\n",
    "                    ])\n",
    "\n",
    "text_clf.fit(train_data, train_targets) \n",
    "print(text_clf)\n",
    "predicted = text_clf.predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(\"\\nConfusion matrix:\")\n",
    "print(metrics.confusion_matrix(test_targets, predicted))\n",
    "print(metrics.classification_report(test_targets, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
