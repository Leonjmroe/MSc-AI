{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6, Lesson 4, Activity 6: Simple LM algorithm\n",
    "\n",
    "&copy;2021, Ekaterina Kochmar \\\n",
    "(revised: Nadejda Roubtsova, June 2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task in this activity is to:\n",
    "\n",
    "- Implement and evaluate a simple language model using the data referenced in the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Define a Language Model class\n",
    "\n",
    "Let's start by importing the libraries and building a Language Model class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "from numpy import cumsum, sum, searchsorted\n",
    "from numpy.random import rand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objects of class `LanguageModel` should be able to:\n",
    "\n",
    "* _estimate_ the transition probabilities from the context of given order (i.e., length of context) to the next characters based on some training text;\n",
    "* _predict_ the next character based on any new context;\n",
    "* _generate_ a whole sequence using its predictions.\n",
    "\n",
    "To this end let's add three public methods to the class `LanguageModel` that will provide all the functionality described above:\n",
    "\n",
    "* `train` to estimate the probabilities;\n",
    "* `predict` to predict next character;\n",
    "* `generate` to generate a whole sequence of characters.\n",
    "\n",
    "In the code below:\n",
    "1. The method `train` learns the transition probabilities from a text, which is represented as a string and provided to the method as an argument `sequence`.\n",
    "2. The `transitions` dictionary keeps the number of times the context of the specified order (length) is followed by the current character.\n",
    "3. The method `predict` chooses the most probable character given the preceding one(s). The preceding one(s) are provided to the method as an argument `symbol`.\n",
    "4. If the length of the provided sequence of the previous characters doesn't match the language model order, report an error.\n",
    "5. Return the character with a given probability.\n",
    "6. The method `generate` allows you to generate a sequence of a specified number (`n`) of characters.\n",
    "7. For that, it calls on the `predict` method providing it with the context `start`.\n",
    "8. It moves the context character by character specified number of `n` times, thus allowing you to generate `n` new characters.\n",
    "9. Method `weighted_pick` provides search functionality for the probabilities.\n",
    "\n",
    "Your task is to read through the code, experiment with it, and make sure you understand the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModel(object):\n",
    "    def __init__(self, order=1):\n",
    "        '''Initializes a language model of the given order.'''\n",
    "        self._transitions = defaultdict(int)\n",
    "        self._order = order\n",
    "        \n",
    "    def train(self, sequence):\n",
    "        '''Trains the model using sequence.'''\n",
    "        self._symbols = list(set(sequence))\n",
    "        for i in range(len(sequence)-self._order):\n",
    "            self._transitions[sequence[i:i+self._order], sequence[i+self._order]] += 1\n",
    "\n",
    "    def predict(self, symbol):\n",
    "        '''Takes as input a string and predicts the next character.'''\n",
    "        if len(symbol) != self._order:\n",
    "            raise ValueError('Expected string of %d chars, got %d' % (self._order, len(symbol)))\n",
    "        probs = [self._transitions[(symbol, s)] for s in self._symbols]\n",
    "        return self._symbols[self._weighted_pick(probs)]\n",
    "\n",
    "    def generate(self, start, n):\n",
    "        '''Generates n characters from start.'''\n",
    "        result = start\n",
    "        for i in range(n):\n",
    "            new = self.predict(start)\n",
    "            result += new\n",
    "            start = start[1:] + new\n",
    "        return result\n",
    "\n",
    "    @staticmethod\n",
    "    def _weighted_pick(weights):\n",
    "        '''Weighted random selection returns n_picks random indexes.\n",
    "        The chance to pick the index i is given by weights[i].'''\n",
    "        return searchsorted(cumsum(weights), rand()*sum(weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Use your Language Model in practice\n",
    "\n",
    "Let's try to generate texts using famous books to train the language model. In that case, you should expect to get the generated text that is quite similar in style to the text of the book you trained your language model on.\n",
    "\n",
    "Let's import [urllib](https://docs.python.org/3.0/library/urllib.request.html) that will allow you to access texts from online resources. You can download a book from a collection of [Gutenberg Project books](https://www.gutenberg.org) available online. Let's start with *Robinson Crusoe*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "651508\n",
      "﻿The Project Gutenberg eBook of The Life and Adventures of Robinson Crusoe,\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "in_text = \"\"\n",
    "with urlopen('https://www.gutenberg.org/files/521/521-0.txt') as response:\n",
    "    for line in response:\n",
    "        line = line.decode('utf-8')  # Decoding the binary data to text.\n",
    "        in_text += line\n",
    "        \n",
    "print(type(in_text))\n",
    "print(len(in_text))\n",
    "print(in_text[:75])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This piece of code downloads Robinson Crusoe and puts all the contents of this book in a (very long) string.\n",
    "Let's now train your language model and generate new text, for example, using a context of 4 previous characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your monstances more of ours, we tree of me in my devils, so overnor’s sands and\n",
      "land, and but we\n",
      "with\n"
     ]
    }
   ],
   "source": [
    "model = LanguageModel(order=4)\n",
    "model.train(in_text)\n",
    "# Note that to generate text with a context (order) of specific length,\n",
    "# you need to provide the context of that length: e.g., len('your')=4 here\n",
    "print (model.generate('your', 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with examples of texts of your own choice. E.g., here's Shakespeare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "book = 'http://www.gutenberg.org/cache/epub/1112/pg1112.txt' # Romeo and Juliet\n",
    "\n",
    "# use the code similar to the steps above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Evaluate your Language Model\n",
    "\n",
    "The most widely used measure of the language model performance is *perplexity*, which measures how probable in the language the piece of text generated by a language model is. Let's implement this measure and evaluate the text generated by the language models above.\n",
    "\n",
    "The first step is to collect the data which you will use to calculate probabilities. You can use some text from before as the data for perplexity estimation. \n",
    "\n",
    "The data contains strings of symbols (characters) and before calculating the probabilities of words, you need to tokenise it into constituent words. Let's use `spaCy` for that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'en_core_web_md'. It doesn't seem to be a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m nlp \u001b[38;5;241m=\u001b[39m \u001b[43mspacy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43men_core_web_md\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m tokens \u001b[38;5;241m=\u001b[39m nlp(in_text)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(tokens))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/spacy/__init__.py:51\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\n\u001b[1;32m     28\u001b[0m     name: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m     config: Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Config] \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mSimpleFrozenDict(),\n\u001b[1;32m     35\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Language:\n\u001b[1;32m     36\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;03m    name (str): Package name or model path.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43menable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/spacy/util.py:472\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m OLD_MODEL_SHORTCUTS:\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE941\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname, full\u001b[38;5;241m=\u001b[39mOLD_MODEL_SHORTCUTS[name]))  \u001b[38;5;66;03m# type: ignore[index]\u001b[39;00m\n\u001b[0;32m--> 472\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE050\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname))\n",
      "\u001b[0;31mOSError\u001b[0m: [E050] Can't find model 'en_core_web_md'. It doesn't seem to be a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "tokens = nlp(in_text)\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's estimate unigram (word-based) probabilities in this data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigram(tokens):    \n",
    "    model = defaultdict(lambda: 0.001)\n",
    "    for token in tokens:\n",
    "        token = str(token).strip()\n",
    "        model[token] += 1\n",
    "       \n",
    "    total = 0\n",
    "    # calculate the total number of occurrences of all words and store as total\n",
    "    \n",
    "    for word in model:\n",
    "        model[word] = model.get(word)/float(total)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's estimate perplexity using the formula from the lecrtures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity(testset, model):\n",
    "    testset = nlp(testset)\n",
    "    perplexity = 1\n",
    "    N = 0\n",
    "    for word in testset:\n",
    "        N += 1\n",
    "        perplexity = perplexity * (1/model[str(word).strip()])\n",
    "    perplexity = pow(perplexity, 1/float(N)) \n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, that a good language model will generate a highly probable sequence of words. Recall from the lecture that lower perplexity values signify better models. When you use perplexity to measure the quality of and to compare several language models, you are looking for the one that has **lower perplexity**.\n",
    "\n",
    "With all the components in place, let's apply this measurement and compare a language model that generates text using previous $4$ characters with the one that uses previous $6$ characters. The more likely the words generated by the language model are, the lower the perplexity score. Which model is better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_data = in_text\n",
    "model = unigram(tokens)\n",
    "\n",
    "lm1 = # initialise a language model of order=4\n",
    "lm1.train(lm_data)\n",
    "testset1 = # generate some text for testset1 using lm1\n",
    "print(testset1)\n",
    "print(# calculate perplexity for this text according to the model\n",
    "      )\n",
    "\n",
    "print()\n",
    "\n",
    "lm2 = # initialise a language model of order=6\n",
    "lm2.train(lm_data)\n",
    "testset2 = # generate some text for testset1 using lm2\n",
    "print(testset2)\n",
    "print(# calculate perplexity for this text according to the model\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
