{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5339b618-1ebb-49ad-b183-753bd5f048d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data: (1000, 55)\n",
      "Shape of testing data: (500, 55)\n",
      "Accuracy: 0.90\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "training_data = np.loadtxt(open(\"data/training_spam.csv\"), delimiter=\",\")\n",
    "testing_data = np.loadtxt(open(\"data/testing_spam.csv\"), delimiter=\",\")\n",
    "print(\"Shape of training data:\", training_data.shape)\n",
    "print(\"Shape of testing data:\", testing_data.shape)\n",
    "\n",
    "# Splitting the dataset into features and labels\n",
    "X_tr = training_data[:, 1:]  # Features\n",
    "y_tr = training_data[:, 0]  # Labels\n",
    "\n",
    "X_tes = testing_data[:, 1:]  \n",
    "y_tes = testing_data[:, 0] \n",
    "\n",
    "\n",
    "\n",
    "# Calculate prior probabilities P(c) for each class\n",
    "class_labels = np.unique(y_tr)  # Find all unique class labels in the dataset\n",
    "prior_probabilities = {label: (y_tr == label).mean() for label in class_labels}\n",
    "# For each label, calculate the fraction of samples in the dataset that belong to that label\n",
    "\n",
    "# Prepare to calculate likelihoods P(feature|class) using Laplace smoothing\n",
    "laplace_alpha = 1  # Laplace smoothing parameter to avoid division by zero\n",
    "feature_likelihoods = {}  # Initialize a dictionary to store likelihoods for each class\n",
    "\n",
    "# Loop over each class label to calculate feature likelihoods given the class\n",
    "for label in class_labels:\n",
    "    # Select the subset of features corresponding to the current class\n",
    "    feature_subset = X_tr[y_tr == label]\n",
    "    \n",
    "    # Calculate the likelihood of each feature given the class, with Laplace smoothing\n",
    "    # (Sum of feature values in the class + laplace_alpha) divided by \n",
    "    # (Total count of all features in the class + laplace_alpha times number of features)\n",
    "    # This accounts for the possibility of unseen features (i.e., features with zero frequency in the training data for this class)\n",
    "    likelihood = (np.sum(feature_subset, axis=0) + laplace_alpha) / \\\n",
    "                 (np.sum(feature_subset) + laplace_alpha * X_tr.shape[1])\n",
    "    \n",
    "    # Store the calculated likelihoods for the class in the feature_likelihoods dictionary\n",
    "    feature_likelihoods[label] = likelihood\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def predict(X_new, prior_probabilities, feature_likelihoods):\n",
    "    \n",
    "    # Convert prior probabilities to log scale to prevent numerical underflow\n",
    "    # This is necessary because multiplying many small probabilities can lead to underflow,\n",
    "    # where the computer represents the number as zero. Logarithms prevent this by\n",
    "    # transforming multiplication of probabilities into addition of logs.\n",
    "    log_priors = np.log(list(prior_probabilities.values()))\n",
    "    \n",
    "    # Initialize a list to store predictions for each sample in X_new\n",
    "    predictions = []\n",
    "\n",
    "    # Iterate over each sample in the new dataset\n",
    "    for x in X_new:\n",
    "\n",
    "        # Compute the log likelihoods for each class given the sample\n",
    "        # This is done by summing the logs of the feature likelihoods, weighted by the feature values in the sample\n",
    "        # The use of log likelihoods (instead of raw likelihoods) is another measure to prevent numerical underflow\n",
    "        log_likelihoods = np.array([np.sum(np.log(feature_likelihoods[label]) * x) for label in class_labels])\n",
    "        \n",
    "        # Calculate the log posterior probability for each class\n",
    "        # This is the sum of the log prior and the log likelihood for each class\n",
    "        # The log posterior is proportional to the probability of the class given the sample,\n",
    "        # but we don't need to calculate the exact probability because we only need to know which class is most likely\n",
    "        log_posterior = log_priors + log_likelihoods\n",
    "\n",
    "        # Choose the class with the highest log posterior probability as the prediction for the current sample\n",
    "        # np.argmax returns the index of the maximum value in log_posterior, which corresponds to the most likely class\n",
    "        predictions.append(np.argmax(log_posterior))\n",
    "\n",
    "    # Return the predictions as a numpy array for consistency and ease of use\n",
    "    return np.array(predictions)\n",
    "\n",
    "\n",
    "\n",
    "def calculate_accuracy(predictions, actual_classes):\n",
    "\n",
    "    # Ensure predictions and actual_classes are numpy arrays to support element-wise comparison\n",
    "    predictions = np.array(predictions)\n",
    "    actual_classes = np.array(actual_classes)\n",
    "    \n",
    "    # Calculate the number of correct predictions\n",
    "    correct_predictions = np.sum(predictions == actual_classes)\n",
    "    \n",
    "    # Calculate the accuracy: ratio of correct predictions to total number of predictions\n",
    "    accuracy = correct_predictions / len(actual_classes)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "\n",
    "\n",
    "predictions = predict(X_tes, prior_probabilities, feature_likelihoods)\n",
    "accuracy = calculate_accuracy(predictions, y_tes)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fb22c258-8877-40f1-8c81-15f674cc2b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: array([0.02152484, 0.01227117, 0.03419835, 0.00040233, 0.02816335,\n",
       "        0.01287467, 0.00261517, 0.00824784, 0.01086301, 0.02051901,\n",
       "        0.00764434, 0.05310803, 0.01629451, 0.00563267, 0.002414  ,\n",
       "        0.01227117, 0.01307584, 0.01629451, 0.06920137, 0.00261517,\n",
       "        0.04224502, 0.001207  , 0.00341984, 0.00261517, 0.04667069,\n",
       "        0.03460068, 0.03299135, 0.01931201, 0.01629451, 0.01830618,\n",
       "        0.01247234, 0.009656  , 0.01367934, 0.00985717, 0.01911084,\n",
       "        0.02072018, 0.03540535, 0.002414  , 0.01408167, 0.01227117,\n",
       "        0.00563267, 0.01528867, 0.01307584, 0.01247234, 0.03641118,\n",
       "        0.02112251, 0.002414  , 0.00744317, 0.02273184, 0.0683967 ,\n",
       "        0.01810501, 0.03580768, 0.01287467, 0.01066184]),\n",
       " 1.0: array([0.02892562, 0.02380952, 0.04565132, 0.00137741, 0.04998032,\n",
       "        0.03168044, 0.03109012, 0.02754821, 0.02282566, 0.03620622,\n",
       "        0.02282566, 0.04781582, 0.02459662, 0.00964187, 0.01082251,\n",
       "        0.04348682, 0.0334514 , 0.02676112, 0.06847698, 0.01731602,\n",
       "        0.06198347, 0.00373869, 0.02499016, 0.03069658, 0.00236128,\n",
       "        0.00177096, 0.00039355, 0.00118064, 0.00098386, 0.00078709,\n",
       "        0.00039355, 0.00019677, 0.00255805, 0.00019677, 0.00314837,\n",
       "        0.00550964, 0.00472255, 0.00137741, 0.00334514, 0.01042896,\n",
       "        0.00019677, 0.00059032, 0.00491932, 0.00098386, 0.0210547 ,\n",
       "        0.00255805, 0.00118064, 0.00078709, 0.01259347, 0.04860291,\n",
       "        0.00708383, 0.06513184, 0.04820937, 0.0210547 ])}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_likelihoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b97da3d3-7014-45a6-930e-5a6703c0a76c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 0.613, 1.0: 0.387}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6501bd3f-bba7-4ca4-b40d-76caf34a8871",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
