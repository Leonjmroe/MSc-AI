{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6c9de3e-9e6b-483a-94b4-5192362015f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.896\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class NaiveBayesClassifier:\n",
    "    def __init__(self, training_data, testing_data):\n",
    "        self.training_data = training_data\n",
    "        self.testing_data = testing_data\n",
    "        \n",
    "    \n",
    "    \n",
    "    def probability_calc(self):\n",
    "        label_arr = self.training_data[:, 0]\n",
    "        # Initialise dictionaries for storing prior probabilities and feature probabilities\n",
    "        prior_probs = {}\n",
    "        all_feature_probs = {}\n",
    "        # Laplace smoothing factor to avoid division by zero\n",
    "        laplace_alpha = 1\n",
    "        unique_labels = np.unique(label_arr)\n",
    "        \n",
    "        for label in unique_labels:\n",
    "            # Count occurrences of each class label to calculate prior probabilities\n",
    "            label_count = np.sum(label == label_arr)\n",
    "            prior_probs[label] = np.log(label_count / len(label_arr))\n",
    "            probabilities = np.array([])\n",
    "    \n",
    "            # Initialise dictionary for storing probabilities of each feature given the class\n",
    "            feature_probs = {}\n",
    "            # Extract rows corresponding to the current class\n",
    "            features = self.training_data[self.training_data[:, 0] == label][:, 1:]\n",
    "    \n",
    "            for feature in range(np.shape(features[0])[0]):  # Loop through all features \n",
    "                # Calculate probability of each feature given the class with Laplace smoothing\n",
    "                prob = np.log((np.sum(features[:, feature]) + laplace_alpha) / \\\n",
    "                       (len(features) + laplace_alpha * 2))  # Corrected smoothing formula\n",
    "                probabilities = np.append(probabilities, prob) \n",
    "            \n",
    "            all_feature_probs[label] = probabilities  \n",
    "            \n",
    "        return prior_probs, all_feature_probs\n",
    "\n",
    "\n",
    "\n",
    "    def testing(self, prior_probs, all_feature_probs, test_element):\n",
    "        label_probs = {}\n",
    "        for label in np.unique(self.training_data[:, 0]):\n",
    "            probabilities = np.array([])\n",
    "            \n",
    "            for feature in range(len(test_element) - 1):  # Skip label in test_element\n",
    "                if test_element[feature + 1] == 1:  # Consider feature if present\n",
    "                    feature_prob = all_feature_probs[label][feature]  \n",
    "                    final_prob = prior_probs[label] + feature_prob\n",
    "                    probabilities = np.append(probabilities, final_prob)\n",
    "            \n",
    "            # Calculate class probability by multiplying prior with product of feature probabilities\n",
    "            label_probs[label] = np.sum(probabilities)\n",
    "    \n",
    "        # Predict class with highest probability\n",
    "        prediction = max(label_probs, key=label_probs.get)\n",
    "        return prediction\n",
    "\n",
    "\n",
    "\n",
    "    def predictor(self, prior_probs, all_feature_probs):\n",
    "        predictions = np.array([])\n",
    "        for test_element in test_data:\n",
    "            prediction = self.testing(prior_probs, all_feature_probs, test_element)\n",
    "            predictions = np.append(predictions, prediction)\n",
    "        return predictions\n",
    "\n",
    "\n",
    "    \n",
    "    def run(self):\n",
    "        prior_probs, all_feature_probs = self.probability_calc()\n",
    "        predictions = self.predictor(prior_probs, all_feature_probs)\n",
    "        accuracy = np.sum(predictions == self.testing_data[:, 0]) / len(self.testing_data[:, 0])\n",
    "        return accuracy \n",
    "\n",
    "\n",
    "\n",
    "naive_bayes = NaiveBayesClassifier(training_data, testing_data)\n",
    "accuracy = naive_bayes.run()\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ee985d-bef7-43e1-a832-b870be63b9e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
