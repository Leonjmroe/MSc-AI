{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d3616c1",
   "metadata": {},
   "source": [
    "# Robotics and Machine Vision â€“ Image Warping Lab\n",
    "\n",
    "Last edited by Nadejda Roubtsova for September - October 2024 \n",
    "\n",
    "This lab will explore image warping.\n",
    "\n",
    "You should download the **supporting images** `mona.jpg` and `windows.jpg` from the assignment's webpage, and put them into the same directory as this notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0afb435",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dccee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make figures larger.\n",
    "plt.rcParams['figure.figsize'] = [10, 6]\n",
    "\n",
    "## Try commenting this out if plots look blurry on your screen.\n",
    "# %config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e29ccd5",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Forward mapping [15 marks]\n",
    "\n",
    "Let us start by implementing image warping using forward mapping.\n",
    "Every pixel in the source image is transformed to the target image independently. You will see that this approach leads to gaps between the transformed pixels in the target image.\n",
    "\n",
    "\n",
    "\n",
    "Let's first load the image and define an example warping transformation for this assignment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c4306f",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = plt.imread('mona.jpg') / 255.\n",
    "\n",
    "## Basic transformations to manipulate the source image.\n",
    "T = np.array([[1, 0, -source.shape[1] / 2],\n",
    "              [0, 1, -source.shape[0] / 2],\n",
    "              [0, 0, 1]])\n",
    "t = np.pi / 4\n",
    "R = np.array([[np.cos(t), -np.sin(t), 0],\n",
    "              [np.sin(t),  np.cos(t), 0],\n",
    "              [ 0, 0, 1]])\n",
    "S = np.diag([2, 2, 1])\n",
    "\n",
    "## The warping transformation (rotation about arbitrary point).\n",
    "M = np.linalg.inv(T) @ R @ S @ T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c34ead1",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> **For you to do:** </span>\n",
    "\n",
    "**a) Implement a function to transform a point (x, y) using a homogeneous 2D transform matrix, rounding to the nearest pixel. [5 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26c65b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_pixel_nn(x, y, transform):\n",
    "    \"\"\"Transforms a source pixel coordinate (x, y) using 'transform', and rounds to the nearest pixel\n",
    "    coordinate. Returns a tuple (x', y').\"\"\"\n",
    "    ##  Replace this code with your own implementation.\n",
    "    return (0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cc0d41",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> **For you to do:** </span>\n",
    "\n",
    "**b) Implement forward mapping using your per-pixel transform function. The pixel grid is meant to be kept consistent between the source and target. [10 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6d481b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_mapping(source, transform):\n",
    "    \"\"\"Warps the 'source' image by the given 'transform' using forward mapping.\"\"\"\n",
    "    ## Replace this code with your own implementation.\n",
    "    return np.zeros_like(source)\n",
    "\n",
    "\n",
    "## Visualise input (left) and warped output (right).\n",
    "target = forward_mapping(source, M)\n",
    "plt.imshow(np.hstack([source, target]))\n",
    "plt.axis(\"off\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6453942",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Backward mapping [20 marks]\n",
    "\n",
    "<span style=\"color:red\"> **For you to do:** </span>\n",
    "\n",
    "**a) Using the `transform_pixel_nn` function from your implementation of forward mapping implement backward mapping in the code cell below using the same 2D transformation `M`.**\n",
    "\n",
    "Backward mapping computes for each **target image pixel** where in the source image it originats from, and, in its simplest form, uses the colour sampled from the nearest pixel. Note that this operation should not leave any gaps in the warped image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38efabd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_mapping(source, transform):\n",
    "    \"\"\"Warps the 'source' image by the given 'transform' using backward mapping with nearest-neighbour interpolation.\"\"\"\n",
    "    ## Replace this code with your own implementation.\n",
    "    return np.zeros_like(source)\n",
    "\n",
    "\n",
    "## Visualise input (left) and warped output (right).\n",
    "target = backward_mapping(source, M)\n",
    "plt.imshow(np.hstack([source, target]))\n",
    "plt.axis(\"off\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d9bd4e",
   "metadata": {},
   "source": [
    "## 3. Linear interpolation [20 marks]\n",
    "\n",
    "<span style=\"color:red\"> **For you to do:** </span>\n",
    "\n",
    "**a) In the code cell below, modify your backward mapping function from part 2 to sample pixel colours from the source image using bilinear interpolation. [15 marks]**\n",
    "\n",
    "**b) Handle the edge cases carefully for full marks. Specifically, implement the \"fading to black\" effect at the edges of the interpolated image by carefully considering how to handle the off-the-image grid pixels of the source image during interpolation. [5 marks]**\n",
    "\n",
    "**Hint:** For validation, it may be helpful to use the transformations `M` commented out in the code cell below.\n",
    "\n",
    "Interpolation must be implemented from scratch, not using any exisiting library functions. Note that interpolation may require a different precision of mapping and/or rounding approach to anchor to the pixel grid. So, in this question, feel free **not** to use `transform_pixel_nn` from Q1 a), which rounds off to the nearest pixel, or to write a *modified* version of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225ca5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_mapping_bilinear(source, transform):\n",
    "    \"\"\"Warps the 'source' image by the given 'transform' using backward mapping with bilinear interpolation.\"\"\"\n",
    "    ## Replace this code with your own implementation to satify 3a and 3b\n",
    "    return np.zeros_like(source)\n",
    "\n",
    "\n",
    "## Compare nearest-neighbour (left) and bilinear interpolation (right) side by side.\n",
    "M = np.array([[12, 0, -2486], [0, 12, -2508], [0, 0, 1]])  # big smile\n",
    "# M = np.array([[40, 0, 80], [0, 40, 80], [0, 0, 1]])  # check edge handling\n",
    "target_nearest  = backward_mapping(source, M)\n",
    "target_bilinear = backward_mapping_bilinear(source, M)\n",
    "plt.imshow(np.hstack([target_nearest, target_bilinear]))\n",
    "plt.axis(\"off\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3121141f",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Lens undistortion [45 marks]\n",
    "\n",
    "In this part of the assignment, you will apply a different warping function, speficifically one that can be used to remove lens distortion from images. The visual effect of such *un-*distortion is rectification of lines so that they appear straight again.\n",
    "\n",
    "Undistortion is to be implemented via backward mapping. To this end, consider the steps to map a target image location $(u,v)$ onto the source image location $(u', v')$ using the *polynomial lens distortion model*:\n",
    "\n",
    "$$\\begin{align}\n",
    "x &= (u - p_x) / f_x \\\\\n",
    "y &= (v - p_y) / f_y \\\\\n",
    "r^2 &= x^2 + y^2 \\\\\n",
    "x' &= x \\cdot (1 + k_1 r^2 + k_2 r^4 + k_3 r^6) \\\\\n",
    "y' &= y \\cdot (1 + k_1 r^2 + k_2 r^4 + k_3 r^6) \\\\\n",
    "u' &= x' \\cdot f_x + p_x \\\\\n",
    "v' &= y' \\cdot f_y + p_y\n",
    "\\end{align}$$\n",
    "\n",
    "In the mapping above:\n",
    "* $f_x$ and $f_y$ are the focal lengths of the camera\n",
    "* $(p_x, p_y)$ is called the *principal point* or *centre of projection*\n",
    "* $k_1$, $k_2$, $k_3$ are the *lens distortion coefficients*\n",
    "\n",
    "Further please note that:\n",
    "* The `camera_matrix` is defined as:\n",
    "\n",
    "  $\\mathbf{K} = \\begin{bmatrix}f_x & 0 & p_x \\\\ 0 & f_y & p_y \\\\ 0 & 0 & 1\\end{bmatrix}$.\n",
    "  \n",
    "\n",
    "* `dist_coeffs` is the lens distortion coefficients $\\begin{bmatrix}k_1 & k_2 & k_3\\end{bmatrix}$ .\n",
    "\n",
    "<span style=\"color:red\"> **For you to do:** </span>\n",
    "\n",
    "**a) Implement the steps of the polynomial distortion model detailed above in the function below to calculate the source image location $(u', v')$  for a single given pixel $(u,v)$ of the target (undistorted) image. [5 marks]**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1eeb7e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def undistort_point(u, v, camera_matrix, dist_coeffs):\n",
    "    \"\"\"Given camera matrix and distortion coefficients, finds the corresponding undistorted (source) pixel location (u', v') \n",
    "    for a given (target) pixel location (u,v).\"\"\"\n",
    "    ## Replace this code with your own implementation.\n",
    "    return 0, 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c59c07",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> **For you to do:** </span>\n",
    "\n",
    "**b) Using your function `undistort_point` above, in the code cell below implement polynomial lens undistortion for a given image via backward mapping with bilinear interpolation. [15 marks]**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b67e5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def undistort_image(image, camera_matrix, dist_coeffs):\n",
    "    \"\"\"Undistorts an image using the given camera matrix and distortion coefficients.\"\"\"\n",
    "    ## Replace this code with your own implementation.\n",
    "    return np.zeros_like(image)\n",
    "\n",
    "\n",
    "## The intrinsic camera matrix and lens undistortion coefficients for the test image.\n",
    "source = plt.imread('window.jpg') / 255.\n",
    "camera_matrix = np.array([[474.53, 0, 405.96], [0, 474.53, 217.81], [0, 0, 1]])\n",
    "dist_coeffs = np.array([-0.27194, 0.11517, -0.029859])\n",
    "\n",
    "## Visualise input (top) and undistorted output (bottom).\n",
    "target_unvectorised = undistort_image(source, camera_matrix, dist_coeffs)\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "plt.imshow(np.vstack([source, target_unvectorised]))\n",
    "plt.axis(\"off\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e303f8",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> **For you to do:** </span>\n",
    "\n",
    "**c) Implement fast image undistortion using vectorisation, without any for-loops. Your function should run in less than 3 seconds. [15 marks]**\n",
    "\n",
    "Remember that the vectorised version of your undistortion function must be functionally identical to the original. This means the function must also perform bilinear interpolation.\n",
    "\n",
    "This is the advanced question of the assignment, so it will be marked stricter than 4b in terms of correctness of output and performance, with partial credit awarded only rarely. Watch out for hidden for-loops in your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bab7052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def undistort_image_vectorised(image, camera_matrix, dist_coeffs):\n",
    "    \"\"\"Undistorts an image using the given camera matrix and distortion coefficients.\n",
    "    Use vectorised operations to avoid slow for-loops.\"\"\"\n",
    "    ## Replace this code with your own implementation.\n",
    "    return np.zeros_like(image)\n",
    "\n",
    "\n",
    "# Visualise input (top) and undistorted output (bottom).\n",
    "target_vectorised = undistort_image_vectorised(source, camera_matrix, dist_coeffs)\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "plt.imshow(np.vstack([source, target_vectorised]))\n",
    "plt.axis(\"off\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2669a4",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> **For you to do:** </span>\n",
    "\n",
    "**d) Show that both the original and the vectorised implementations produce the same result by running the cell below. [10 marks]**\n",
    "\n",
    "Partial credit will be awarded if the outputs are consistent with each other but not completely correct. If the output is completely wrong given the task (e.g., not undistorted), no credit will be awarded.\n",
    "\n",
    "Note that for consistent outputs the difference below will be very small (say, order of e-15) but not completely zero.\n",
    "\n",
    "If you find a discrepancy between the outputs, go back and debug the relevant implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59979f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "difference = np.sum(np.abs(target_unvectorised - target_vectorised))\n",
    "print(difference)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "684ad323d589ebb2ff4538e4e53a639ca5d21159d2a25fb2a275452014667af7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
